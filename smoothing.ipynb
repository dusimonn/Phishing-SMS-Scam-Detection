{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2025 Semester 1\n",
    "\n",
    "## Assignment 1: Scam detection with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     `1352062`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, GRAPHS, AND FIGURES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).** Results, figures, etc. which appear in this file but are NOT included in your report will not be marked.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Infrastructure and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tokens(processed_text):\n",
    "    \"\"\"\n",
    "    Given a preprocessed string/instance, return its tokens and their counts.\n",
    "    \"\"\"\n",
    "    token_counts = dict()\n",
    "    \n",
    "    if isinstance(processed_text, str):\n",
    "        # Split the string into words/tokens\n",
    "        processed_text = processed_text.split(\" \")\n",
    "        # Count the occurrences of each token\n",
    "        for token in processed_text:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "    else:\n",
    "        # Empty string classified as a float for some reason\n",
    "        token_counts = {\"\": 1}\n",
    "\n",
    "    return token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vocabulary(data):\n",
    "    \"\"\"\n",
    "    Find the list of every word which occurs in the  dataset (every word in textPreprocessed)\n",
    "    \"\"\"\n",
    "    vocabulary = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        processed_text = return_tokens(data.loc[i, \"textPreprocessed\"]).keys()\n",
    "        vocabulary = vocabulary + list(processed_text)\n",
    "\n",
    "    vocabulary = sorted(list(set(vocabulary)))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_count_matrix(data, vocabulary):\n",
    "    \"\"\"\n",
    "    Find the count matrix, which is a matrix of size N*V where N is the number of instances in the training data \n",
    "    and V is the number of words in the vocabulary.  \n",
    "    Each cell in the matrix represents the number of times a given word appeared in a given message \n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    # Intialise matrix N*V with 0s\n",
    "    count_matrix = np.zeros((N,V))\n",
    "    count_matrix = pd.DataFrame(count_matrix)\n",
    "    count_matrix.columns = vocabulary\n",
    "\n",
    "    # Iterate over each row - instance \n",
    "    for i in range(N):\n",
    "        instance_token_counts = return_tokens(data.loc[i, \"textPreprocessed\"])\n",
    "        for token in instance_token_counts.keys():\n",
    "            count_matrix.loc[i, token] = instance_token_counts[token]\n",
    "    \n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_prob(data):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of the prior probability of each class P(class)\n",
    "    \"\"\"\n",
    "    prior_probs = dict()\n",
    "\n",
    "    labels = np.unique(data[\"class\"])\n",
    "    for label in labels:\n",
    "        prior_probs[int(label)] = len(data[data[\"class\"]==label])/len(data)\n",
    "\n",
    "    return prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_p_c_i(data, count_matrix, label, word, V=0, alpha=0):\n",
    "    \"\"\"\n",
    "    p(word | label) = count(c,i) + alpha / total(c) + V*alpha\n",
    "    count(c,i) is the total count of times word i appears in messages from class c\n",
    "    total(c) is the total count of words in class c\n",
    "    Alpha is smoothing factor used for Laplace smoothing, defaulted to 0 (no smoothing)\n",
    "    V is the length of the count vector of a test instance\n",
    "    \"\"\"\n",
    "    label_indexes = data[data[\"class\"] == label].index\n",
    "    count_matrix = count_matrix.iloc[label_indexes]\n",
    "    word_counts = np.sum(count_matrix[word]) + alpha\n",
    "    label_counts = np.sum(count_matrix, axis=0).sum() + (V*alpha)\n",
    "    \n",
    "    return float(word_counts / label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conditional_prob(data, vocabulary, count_matrix):\n",
    "    \"\"\"\n",
    "    Return dictionary conditional probabilities of each token in a class\n",
    "    \"\"\"\n",
    "    conditional_probs = {int(label): None for label in data[\"class\"].unique()}\n",
    "    for label in conditional_probs.keys():\n",
    "        conditional_probs[label] = {word: 0 for word in vocabulary}\n",
    "\n",
    "        for word in vocabulary:\n",
    "            conditional_probs[label][word] = calc_p_c_i(data, count_matrix, label, word, V=len(vocabulary), alpha=1)\n",
    "    \n",
    "    return conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_test_count_vector(test_text, vocabulary):\n",
    "    \"\"\"\n",
    "    Find the count vector of a test instance\n",
    "    \"\"\"\n",
    "    count_vector = np.zeros((1, len(vocabulary)))[0]\n",
    "    test_token_counts = return_tokens(test_text)\n",
    "\n",
    "    for i in range(len(vocabulary)):\n",
    "        token = vocabulary[i]\n",
    "        if token in test_token_counts.keys():\n",
    "            count_vector[i] = test_token_counts[token]\n",
    "    \n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_posterior_prob(data, count_vector, vocabulary, prior_probs, conditional_probs):\n",
    "    \"\"\"\n",
    "    Find posterior probability P(class = label | count = count vector) -> P(class = label) * P(count|c)\n",
    "    \"\"\"\n",
    "    posterior_probs = {int(label): None for label in data[\"class\"].unique()}\n",
    "    for label in posterior_probs.keys():\n",
    "        p_class = prior_probs[label]\n",
    "        p_count_c = math.factorial(int(sum(count_vector))) / math.prod([math.factorial(int(x)) for x in count_vector])\n",
    "        test_token_indexes = [i for i in range(len(count_vector)) if count_vector[i] != 0]\n",
    "\n",
    "        for token_index in test_token_indexes:\n",
    "            p_c_i = conditional_probs[label][vocabulary[token_index]]\n",
    "\n",
    "            # Original formula\n",
    "            p_count_c = p_count_c * math.pow(p_c_i, count_vector[token_index])\n",
    "\n",
    "            # Or take log to avoid underflow\n",
    "            # prob = math.pow(p_c_i, count_vector[token_index])\n",
    "            # if prob == 0:\n",
    "            #     p_count_c = p_count_c + 0\n",
    "            # else:\n",
    "            #     p_count_c = p_count_c + math.log(prob)\n",
    "            \n",
    "        p_c_count = p_class * p_count_c\n",
    "        posterior_probs[label] = p_c_count\n",
    "\n",
    "    return posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_instance(data, vocabulary, test_text, prior_probs, conditional_probs):\n",
    "    \"\"\"\n",
    "    Given a string, classify it as 0 - non malicious, or 1 - scam\n",
    "    \"\"\"\n",
    "    test_count_vector = find_test_count_vector(test_text, vocabulary)\n",
    "\n",
    "    # Count vector all zeroes so cannot classify\n",
    "    if np.count_nonzero(test_count_vector) == 0:\n",
    "        print(\"Cannot classify\")\n",
    "        print(test_text)\n",
    "        return None\n",
    "    \n",
    "    test_posterior_prob = find_posterior_prob(data, test_count_vector, vocabulary, prior_probs, conditional_probs)\n",
    "    # Find which class has higher likelihood\n",
    "    best_label = None\n",
    "    best_prob = 0\n",
    "\n",
    "    # If both are equal, return 0.5, hard coded \n",
    "    if test_posterior_prob[0] == test_posterior_prob[1]:\n",
    "        return 0.5\n",
    "\n",
    "    for label, prob_label in test_posterior_prob.items():\n",
    "        if prob_label > best_prob:\n",
    "            best_prob = prob_label\n",
    "            best_label = label\n",
    "    \n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_prob_ratio(c1, c2, vocabulary, conditional_probs, top=10):\n",
    "    ratios = dict()\n",
    "\n",
    "    for word in vocabulary:\n",
    "        p_c1_i = conditional_probs[c1][word]\n",
    "        p_c2_i = conditional_probs[c2][word]\n",
    "        if p_c2_i != 0:\n",
    "            r = p_c1_i / p_c2_i\n",
    "            ratios[word] = r\n",
    "\n",
    "    top_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    top_ratios = dict(top_ratios)\n",
    "\n",
    "    return top_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_test_ratios(data, vocabulary, prior_probs, conditional_probs, c1, c2, boundary=False, top=3):\n",
    "    ratios = dict()\n",
    "\n",
    "    for test_text in data[\"textPreprocessed\"]:\n",
    "        test_count_vector = find_test_count_vector(test_text, vocabulary)\n",
    "        test_posterior_prob = find_posterior_prob(data, test_count_vector, vocabulary, prior_probs, conditional_probs)\n",
    "        post_c1 = test_posterior_prob[c1]\n",
    "        post_c2 = test_posterior_prob[c2]\n",
    "\n",
    "        if post_c2 != 0:\n",
    "            r = post_c1/post_c2\n",
    "            ratios[test_text] = r\n",
    "\n",
    "    if not boundary:\n",
    "        top_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    else:\n",
    "        top_ratios = sorted(ratios.items(), key=lambda x: abs(x[1] - 1))[:top]\n",
    "\n",
    "    top_ratios = dict(top_ratios)\n",
    "    return top_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sms_supervised_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = find_vocabulary(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = find_count_matrix(train, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = find_prior_prob(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probs = find_conditional_prob(train, vocabulary, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.0000000000000082)\n",
      "(1, 0.9999999999999685)\n"
     ]
    }
   ],
   "source": [
    "# check if prob within each class label sum = 1\n",
    "for label in conditional_probs.keys():\n",
    "    print((label, sum(conditional_probs[label].values())))\n",
    "# good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the prior probabilities of the classes P(c) in the training dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8, 1: 0.2}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the most probable words in each class? List about 10 per class and their probability values p(c,i)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 probable words in class 0\n",
      "1. P(,|class = 0) = 0.026024177300201477\n",
      "2. P(?|class = 0) = 0.025576449518692635\n",
      "3. P(u|class = 0) = 0.0189164987687486\n",
      "4. P(...|class = 0) = 0.018748600850682785\n",
      "5. P(!|class = 0) = 0.017181553615401836\n",
      "6. P(..|class = 0) = 0.014942914707857623\n",
      "7. P(;|class = 0) = 0.013152003581822252\n",
      "8. P(&|class = 0) = 0.013096037609133646\n",
      "9. P(go|class = 0) = 0.01113722856503246\n",
      "10. P(get|class = 0) = 0.009905977165883144\n",
      "\n",
      "\n",
      "Top 10 probable words in class 1\n",
      "1. P(!|class = 1) = 0.02434782608695652\n",
      "2. P(,|class = 1) = 0.023478260869565216\n",
      "3. P(call|class = 1) = 0.020543478260869566\n",
      "4. P(£|class = 1) = 0.01391304347826087\n",
      "5. P(free|class = 1) = 0.010543478260869566\n",
      "6. P(/|class = 1) = 0.009130434782608696\n",
      "7. P(2|class = 1) = 0.008804347826086956\n",
      "8. P(&|class = 1) = 0.008695652173913044\n",
      "9. P(?|class = 1) = 0.008478260869565218\n",
      "10. P(claim|class = 1) = 0.007717391304347826\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_conditional_probs = {}\n",
    "\n",
    "for label in conditional_probs:\n",
    "    prob_dict = conditional_probs[label]\n",
    "    sorted_items = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_conditional_probs[label] = dict(sorted_items)  \n",
    "\n",
    "for label in sorted_conditional_probs:\n",
    "    print(f\"Top 10 probable words in class {label}\")\n",
    "    for i in range(1, 11):\n",
    "        token = list(sorted_conditional_probs[label].keys())[i]\n",
    "        print(f\"{i}. P({token}|class = {label}) = {sorted_conditional_probs[label][token]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What individual words are most strongly predictive of each class? List the words and the probability ratios R. Ignore ratios where the denominator = 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What 10 words are most strongly predictive of the scam (label=1) class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prize': 99.05086956521738,\n",
       " 'tone': 64.09173913043477,\n",
       " '£': 49.71965217391304,\n",
       " 'select': 46.61217391304348,\n",
       " 'claim': 45.96478260869565,\n",
       " 'paytm': 36.901304347826084,\n",
       " 'code': 34.95913043478261,\n",
       " 'award': 32.04586956521739,\n",
       " 'won': 31.074782608695653,\n",
       " '18': 29.13260869565217}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_prob_ratio(c1=1, c2=0, vocabulary=vocabulary, conditional_probs=conditional_probs, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What 10 words are most strongly predictive non-malicious (label=0) class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 60.49921647638236,\n",
       " '...': 57.4957092754272,\n",
       " 'gt': 54.06312961719275,\n",
       " 'lt': 53.548242668457576,\n",
       " ':)': 47.88448623237072,\n",
       " 'ü': 31.922990821580477,\n",
       " 'lor': 28.833669129169465,\n",
       " 'hope': 24.714573539288114,\n",
       " 'ok': 24.714573539288114,\n",
       " 'd': 21.110364898141928}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_prob_ratio(c1=0, c2=1, vocabulary=vocabulary, conditional_probs=conditional_probs, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss results. Do they seem reasonable? Do you think it will be possible to distinguish the 2 classes using the multinomial naive Bayes model? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the most probable words in each class, the top 10 most probable words in each class are filled with punctuation tokens instead of actual words, making it hard to distinguish the 2 classes using this specific Bayes Model. For example, the \"!\" token, appears relatively frequently in both classes, with a probability of approx. 2% and 3% respectively.\n",
    "Thus, more text preprocessing may be needed to reduce the dimensionality of our attributes/tokens/vocabulary, which may result in a more realistic representation of probable words within each label.\n",
    "\n",
    "However, results from the ratio R calculations seem promising and reasonable. The words most strongly predictive of the scam class include \"claim\", \"award\", \"service\", \"£\", which may correspond to typical rewards/money related phishing scams, which is to be expected. Likewise, words most strongly predictive of the non-malicious class such as \"ok\", \"k\", \"sorry\" are typically seen in everyday texts and conversations. \n",
    "\n",
    "Ultimately, it is possible to distinguish the 2 classes using the multinomial naive Bayes model, however, in our specific infrastructure/setup, more data preprocessing of the raw sms could further enhance the model's ability to differentiate between class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"sms_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = test[\"textPreprocessed\"]\n",
    "predicted_labels = []\n",
    "for test_instance in test_instances:\n",
    "    predicted_label = classify_test_instance(test, vocabulary, test_instance, prior_probs, conditional_probs)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "test[\"predicted class\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Report the overall accuracy of your classifier as well as a breakdown by class (e.g. using a confusion matrix or by reporting precision and recall)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove instances where the model could not decide between class 0 or 1 (predict 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_draws = test[test[\"predicted class\"] != 0.5]\n",
    "class_true = test_no_draws[\"class\"]\n",
    "class_predict = test_no_draws[\"predicted class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       800\n",
      "           1       0.93      0.95      0.94       200\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.96      0.97      0.96      1000\n",
      "weighted avg       0.98      0.97      0.98      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(class_true, class_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[785  15]\n",
      " [ 10 190]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAHFCAYAAABb+zt/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/6ElEQVR4nO3de1xVVf7/8feRy+GSkIBwoPAamQYl4iUtw1Ix8/prSkubNMkszTqjpmN+J3GagfA7iamlZSaOVuRUONaYaWVOphWSlprjVOKtILTIKx1u+/eHD8+3I2ocO9sjnNfz8diPR2fttdf+HB7j8OGz1l7bYhiGIQAAAJM08nYAAACgYSPZAAAApiLZAAAApiLZAAAApiLZAAAApiLZAAAApiLZAAAApiLZAAAApiLZAAAApiLZQIP2xRdf6N5771XLli0VFBSkSy65RB06dNDMmTP1448/mnrvLVu2KDU1VeHh4bJYLJo9e7bH72GxWJSRkeHxcX9Nbm6uLBaLLBaLPvjgg1rnDcPQFVdcIYvFoh49epzXPZ599lnl5ua6dc0HH3xw1pgAeI+/twMAzLJw4UKNHTtWbdq00aOPPqp27dqpsrJSmzdv1oIFC7Rp0ybl5+ebdv9Ro0bp+PHjysvLU5MmTdSiRQuP32PTpk26/PLLPT5uXTVu3FiLFi2qlVCsX79e33zzjRo3bnzeYz/77LOKiorSyJEj63xNhw4dtGnTJrVr1+687wvA80g20CBt2rRJDz74oHr37q0VK1bIarU6z/Xu3VsTJ07U6tWrTY1h+/btGj16tPr27WvaPa677jrTxq6LoUOH6qWXXtIzzzyjsLAwZ/uiRYvUtWtXHTly5ILEUVlZKYvForCwMK//TADUxjQKGqTMzExZLBY9//zzLonGKYGBgRo4cKDzc01NjWbOnKmrrrpKVqtV0dHRuueee3TgwAGX63r06KHExEQVFBSoe/fuCgkJUatWrfTkk0+qpqZG0v9NMVRVVWn+/PnO6QZJysjIcP73L526Zs+ePc62999/Xz169FBkZKSCg4PVrFkz/e53v9OJEyecfc40jbJ9+3YNGjRITZo0UVBQkNq3b68lS5a49Dk13fDKK69o2rRpiouLU1hYmHr16qVdu3bV7Ycs6a677pIkvfLKK862w4cP6/XXX9eoUaPOeM2MGTPUpUsXRUREKCwsTB06dNCiRYv0y3dCtmjRQjt27ND69eudP79TlaFTsS9dulQTJ07UZZddJqvVqq+//rrWNMqhQ4cUHx+vbt26qbKy0jn+l19+qdDQUP3+97+v83cFcP5INtDgVFdX6/3331dKSori4+PrdM2DDz6oKVOmqHfv3lq5cqWeeOIJrV69Wt26ddOhQ4dc+paUlGj48OG6++67tXLlSvXt21dTp07VsmXLJEn9+vXTpk2bJEm33367Nm3a5PxcV3v27FG/fv0UGBioF198UatXr9aTTz6p0NBQVVRUnPW6Xbt2qVu3btqxY4fmzJmjN954Q+3atdPIkSM1c+bMWv0fe+wx7d27Vy+88IKef/55ffXVVxowYICqq6vrFGdYWJhuv/12vfjii862V155RY0aNdLQoUPP+t3GjBmj5cuX64033tBtt92m8ePH64knnnD2yc/PV6tWrZScnOz8+Z0+5TV16lTt27dPCxYs0Jtvvqno6Oha94qKilJeXp4KCgo0ZcoUSdKJEyd0xx13qFmzZlqwYEGdvieA38gAGpiSkhJDknHnnXfWqf/OnTsNScbYsWNd2j/55BNDkvHYY48521JTUw1JxieffOLSt127dkafPn1c2iQZ48aNc2mbPn26caZ/dosXLzYkGUVFRYZhGMZrr71mSDK2bt16ztglGdOnT3d+vvPOOw2r1Wrs27fPpV/fvn2NkJAQ46effjIMwzDWrVtnSDJuvfVWl37Lly83JBmbNm06531PxVtQUOAca/v27YZhGEanTp2MkSNHGoZhGFdffbWRmpp61nGqq6uNyspK489//rMRGRlp1NTUOM+d7dpT97vxxhvPem7dunUu7dnZ2YYkIz8/3xgxYoQRHBxsfPHFF+f8jgA8h8oGfN66deskqdZCxM6dO6tt27Z67733XNptNps6d+7s0nbNNddo7969Houpffv2CgwM1P33368lS5Zo9+7ddbru/fffV8+ePWtVdEaOHKkTJ07UqrD8cipJOvk9JLn1XVJTU9W6dWu9+OKL2rZtmwoKCs46hXIqxl69eik8PFx+fn4KCAjQ448/rh9++EGlpaV1vu/vfve7Ovd99NFH1a9fP911111asmSJ5s6dq6SkpDpfD+C3IdlAgxMVFaWQkBAVFRXVqf8PP/wgSYqNja11Li4uznn+lMjIyFr9rFarysvLzyPaM2vdurXeffddRUdHa9y4cWrdurVat26tp59++pzX/fDDD2f9HqfO/9Lp3+XU+hZ3vovFYtG9996rZcuWacGCBbryyivVvXv3M/b99NNPlZaWJunk00IfffSRCgoKNG3aNLfve6bvea4YR44cqZ9//lk2m421GsAFRrKBBsfPz089e/ZUYWFhrQWeZ3LqF25xcXGtc999952ioqI8FltQUJAkyeFwuLSfvi5Ekrp3764333xThw8f1scff6yuXbvKbrcrLy/vrONHRkae9XtI8uh3+aWRI0fq0KFDWrBgge69996z9svLy1NAQIDeeustDRkyRN26dVPHjh3P655nWmh7NsXFxRo3bpzat2+vH374QZMmTTqvewI4PyQbaJCmTp0qwzA0evToMy6orKys1JtvvilJuvnmmyXJucDzlIKCAu3cuVM9e/b0WFynnqj44osvXNpPxXImfn5+6tKli5555hlJ0meffXbWvj179tT777/vTC5O+fvf/66QkBDTHgu97LLL9Oijj2rAgAEaMWLEWftZLBb5+/vLz8/P2VZeXq6lS5fW6uupalF1dbXuuusuWSwWvf3228rKytLcuXP1xhtv/OaxAdQN+2ygQeratavmz5+vsWPHKiUlRQ8++KCuvvpqVVZWasuWLXr++eeVmJioAQMGqE2bNrr//vs1d+5cNWrUSH379tWePXv0pz/9SfHx8frDH/7gsbhuvfVWRUREKD09XX/+85/l7++v3Nxc7d+/36XfggUL9P7776tfv35q1qyZfv75Z+cTH7169Trr+NOnT9dbb72lm266SY8//rgiIiL00ksv6V//+pdmzpyp8PBwj32X0z355JO/2qdfv36aNWuWhg0bpvvvv18//PCD/va3v53x8eSkpCTl5eXp1VdfVatWrRQUFHRe6yymT5+uDz/8UGvWrJHNZtPEiRO1fv16paenKzk5WS1btnR7TADuIdlAgzV69Gh17txZOTk5ys7OVklJiQICAnTllVdq2LBheuihh5x958+fr9atW2vRokV65plnFB4erltuuUVZWVlnXKNxvsLCwrR69WrZ7XbdfffduvTSS3Xfffepb9++uu+++5z92rdvrzVr1mj69OkqKSnRJZdcosTERK1cudK55uFM2rRpo40bN+qxxx7TuHHjVF5errZt22rx4sVu7cRplptvvlkvvviisrOzNWDAAF122WUaPXq0oqOjlZ6e7tJ3xowZKi4u1ujRo3X06FE1b97cZR+Suli7dq2ysrL0pz/9yaVClZubq+TkZA0dOlQbNmxQYGCgJ74egLOwGMYvdtIBAADwMNZsAAAAU5FsAAAAU5FsAAAAU5FsAAAAU5FsAAAAU5FsAAAAU5FsAAAAUzXITb0qD9XtDZmArwmJO/ML0gBfVlnxrfn38NDvpYCoVh4Z50KjsgEAAEzVICsbAABcVGqqvR2BV5FsAABgNqPG2xF4FckGAABmq/HtZIM1GwAAwFRUNgAAMJnBNAoAADAV0ygAAADmobIBAIDZmEYBAACm8vF9NphGAQAApqKyAQCA2ZhGAQAApuJpFAAAAPNQ2QAAwGRs6gUAAMzl49MoJBsAAJjNxysbrNkAAACmorIBAIDZfHxTL5INAADMxjQKAACAeahsAABgNp5GAQAApmIaBQAAwDxUNgAAMBvTKAAAwEyG4duPvjKNAgAATEVlAwAAs/n4AlGSDQAAzMaaDQAAYCofr2ywZgMAAJiKygYAAGbjRWwAAMBUTKMAAACYh8oGAABm8/GnUahsAABgNqPGM4cbWrRoIYvFUusYN27cyZAMQxkZGYqLi1NwcLB69OihHTt2uIzhcDg0fvx4RUVFKTQ0VAMHDtSBAwfc/vokGwAANEAFBQUqLi52HmvXrpUk3XHHHZKkmTNnatasWZo3b54KCgpks9nUu3dvHT161DmG3W5Xfn6+8vLytGHDBh07dkz9+/dXdbV7C14thmEYnvtqF4fKQ7u9HQJwUQqJ6+7tEICLTmXFt6bf4+ePXvLIOEHXDz/va+12u9566y199dVXkqS4uDjZ7XZNmTJF0skqRkxMjLKzszVmzBgdPnxYTZs21dKlSzV06FBJ0nfffaf4+HitWrVKffr0qfO9qWwAAGC2mhrPHOepoqJCy5Yt06hRo2SxWFRUVKSSkhKlpaU5+1itVqWmpmrjxo2SpMLCQlVWVrr0iYuLU2JiorNPXbFAFACAesLhcMjhcLi0Wa1WWa3Wc163YsUK/fTTTxo5cqQkqaSkRJIUExPj0i8mJkZ79+519gkMDFSTJk1q9Tl1fV1R2QAAwGSGUe2RIysrS+Hh4S5HVlbWr95/0aJF6tu3r+Li4lzaLRbLaXEatdpqf5df73M6KhsAAJjNQ4++Tp06VRMmTHBp+7Wqxt69e/Xuu+/qjTfecLbZbDZJJ6sXsbGxzvbS0lJntcNms6miokJlZWUu1Y3S0lJ169bNrbipbAAAYDYPPfpqtVoVFhbmcvxasrF48WJFR0erX79+zraWLVvKZrM5n1CRTq7rWL9+vTORSElJUUBAgEuf4uJibd++3e1kg8oGAAANVE1NjRYvXqwRI0bI3///fuVbLBbZ7XZlZmYqISFBCQkJyszMVEhIiIYNGyZJCg8PV3p6uiZOnKjIyEhFRERo0qRJSkpKUq9evdyKg2QDAACzeWkH0XfffVf79u3TqFGjap2bPHmyysvLNXbsWJWVlalLly5as2aNGjdu7OyTk5Mjf39/DRkyROXl5erZs6dyc3Pl5+fnVhzsswH4EPbZAGq7EPtslL+7wCPjBPd6wCPjXGis2QAAAKZiGgUAALP5+IvYSDYAADCbmy9Ra2iYRgEAAKaisgEAgNmYRgEAAKby8WSDaRQAAGAqKhsAAJjNxxeIkmwAAGA2H59GIdkAAMBsPl7ZYM0GAAAwFZUNAADMxjQKAAAwFdMoAAAA5qGyAQCA2ZhGAQAApvLxZINpFAAAYCoqGwAAmM0wvB2BV5FsAABgNqZRAAAAzENlAwAAs/l4ZYNkAwAAs/n4pl4kGwAAmM3HKxus2QAAAKaisgEAgNl49BUAAJiKaRQAAADzUNkAAMBsPl7ZINkAAMBsPv7oK9MoAADAVFQ2AAAwmVHD0ygAAMBMPr5mg2kUAABgKiobAACYzccXiJJsAABgNtZsAAAAU7FmAwAAwDwkGwAAmK2mxjOHm7799lvdfffdioyMVEhIiNq3b6/CwkLnecMwlJGRobi4OAUHB6tHjx7asWOHyxgOh0Pjx49XVFSUQkNDNXDgQB04cMCtOEg2AAAwm2F45nBDWVmZrr/+egUEBOjtt9/Wl19+qaeeekqXXnqps8/MmTM1a9YszZs3TwUFBbLZbOrdu7eOHj3q7GO325Wfn6+8vDxt2LBBx44dU//+/VVdXV3nWCyG0fDee1t5aLe3QwAuSiFx3b0dAnDRqaz41vR7nJg9xiPjhNifq3PfP/7xj/roo4/04YcfnvG8YRiKi4uT3W7XlClTJJ2sYsTExCg7O1tjxozR4cOH1bRpUy1dulRDhw6VJH333XeKj4/XqlWr1KdPnzrFQmUDbkn73QglXt+31vGXp56RJJ04Ua6/PvWseg6+Wyk3DdKAYfcrL/8tlzFGPjS51vWTHs/yxtcBTHXDDV2Un5+rvXsKVVnxrQYOdP0/5kUv5Kiy4luXY8OHb3opWpjKQ9MoDodDR44ccTkcDscZb7ly5Up17NhRd9xxh6Kjo5WcnKyFCxc6zxcVFamkpERpaWnONqvVqtTUVG3cuFGSVFhYqMrKSpc+cXFxSkxMdPapC55GgVvyXnhaNb+YN/xq916Ntj+mtJtO/sWcPed5ffrZ58p6fLIui43Rxk8L9ZennlF0VKRu7t7Ved3tA2/RQ/f93vnZarVeuC8BXCChoSH64osvtWTJq/rH8hfO2Gf16vd13+gJzs8VFZUXKjxcSB569DUrK0szZsxwaZs+fboyMjJq9d29e7fmz5+vCRMm6LHHHtOnn36qhx9+WFarVffcc49KSkokSTExMS7XxcTEaO/evZKkkpISBQYGqkmTJrX6nLq+Lkg24JaIJpe6fH5h6XLFXxarTslJkqTPt+/UoL691LnDNZKkOwbdqn/8823t2PmVS7IRZLUqKjLigsUNeMM776zTO++sO2cfR0WFvv/+4AWKCPXd1KlTNWHCBJe2s/2xVlNTo44dOyozM1OSlJycrB07dmj+/Pm65557nP0sFovLdYZh1Go7XV36/JJXp1EOHDigadOm6aabblLbtm3Vrl073XTTTZo2bZr279/vzdBQB5WVlXprzTr9v35pzv/RJV9ztdZt+FjfHzwkwzD0aeHn2rPvW13fpYPLtf9au0433DpUg4aP0f/OW6jjx0944ysAXpd6Y1d9e+Bz7djxoRbMn6mmTSO9HRLMYNR45LBarQoLC3M5zpZsxMbGql27di5tbdu21b59+yRJNptNkmpVKEpLS53VDpvNpoqKCpWVlZ21T114rbKxYcMG9e3bV/Hx8UpLS1NaWpoMw1BpaalWrFihuXPn6u2339b111/vrRDxK9779yYdPXZMg2/t7Wx77A8PaPqTT6vn4N/L389PlkYWzfijXR2uTXT26Z92ky6LtSkqsom+2r1HTy/I1a6vivTC05ne+BqA16x+Z51ee/0t7dt3QC1aNNOMjEe1Zs1ydenSVxUVFd4OD57khR1Er7/+eu3atcul7b///a+aN28uSWrZsqVsNpvWrl2r5ORkSVJFRYXWr1+v7OxsSVJKSooCAgK0du1aDRkyRJJUXFys7du3a+bMmXWOxWvJxh/+8Afdd999ysnJOet5u92ugoKCc47jcDhqLY5p5HCwBuACeOOtd3TDdR0V/Yu/xJb945/6Ysd/NC97umJtMSrcuk1/+dszahoZoa6dTv6P+faBfZ39E1q1UPPLL9PQ9If15a6v1a7NFRf8ewDe8o9/rHT+944du1RY+Lm++foT3XprT61Y8bYXI0ND8Ic//EHdunVTZmamhgwZok8//VTPP/+8nn/+eUknp0/sdrsyMzOVkJCghIQEZWZmKiQkRMOGDZMkhYeHKz09XRMnTlRkZKQiIiI0adIkJSUlqVevXnWOxWvTKNu3b9cDDzxw1vNjxozR9u3bf3WcrKwshYeHuxzZTy/wZKg4g+9KvtfHm7fqdwNucbb97HDo6eeW6NGH71ePG65TmytaatjtA3VLzxuV+8rrZx2rXZsr5O/vr737zX/8DLiYlZSUau/eb3XFFS29HQo8zKip8cjhjk6dOik/P1+vvPKKEhMT9cQTT2j27NkaPny4s8/kyZNlt9s1duxYdezYUd9++63WrFmjxo0bO/vk5ORo8ODBGjJkiK6//nqFhITozTfflJ+fX51j8VplIzY2Vhs3blSbNm3OeH7Tpk2KjY391XHOtFim0VF+aZkt/19rFdEkXDd27exsq6qqUlVVlRqdtmjIz6+RyxMsp/u6aK+qqqrUNIoFo/BtERFNFB8fq5KSUm+HAk/z0ovY+vfvr/79+5/1vMViUUZGxhmfZjklKChIc+fO1dy5c887Dq8lG5MmTdIDDzygwsJC9e7dWzExMbJYLCopKdHatWv1wgsvaPbs2b86jtVqrTVlUllxyKSoIZ1c4bziX2s1qG8v+fv/X2Z7SWioOiYn6alnFslqtSrOFq3NW7Zp5dvv6dGHR0uS9h34Tv9as07du3ZSk0vD9U3RXv3vvBfU9srWSk5qd7ZbAvVSaGiIS5WiZYtmuvbaq/Xjj2X68cef9PifJio/f5WKS75X8+bx+ssTf9ShQ2VMoTREvGLeO8aOHavIyEjl5OToueeec2576ufnp5SUFP397393LkbBxWVTwRYVf1+q/9cvrda5v834o2YvyNUfZ8zU4SNHFWeL1sNjRmjo4H6SpICAAH1SuFXL/vFPnSgvly26qW7s1lljRw13qyQH1AcpKdfqvXdfc37+298yJEl///tyjXtoqhITr9Ldd9+uSy8NU3Fxqdav36hhwx/UsWPHvRQxYI6LYrvyyspKHTp0shoRFRWlgICA3zYe25UDZ8R25UBtF2K78uN/Hv7rneog9PGXPDLOhXZRbOoVEBBQp/UZAADUS+fxxtaGhHejAAAAU10UlQ0AABo0Lz2NcrEg2QAAwGw+/jQK0ygAAMBUVDYAADAb0ygAAMBM7m413tAwjQIAAExFZQMAALMxjQIAAExFsgEAAEzFo68AAADmobIBAIDZmEYBAABmMnw82WAaBQAAmIrKBgAAZvPxygbJBgAAZmMHUQAAAPNQ2QAAwGxMowAAAFP5eLLBNAoAADAVlQ0AAExmGL5d2SDZAADAbD4+jUKyAQCA2Xw82WDNBgAAMBWVDQAATObr70Yh2QAAwGw+nmwwjQIAAExFZQMAALP59qtRSDYAADCbr6/ZYBoFAACYisoGAABm8/HKBskGAABm8/E1G0yjAAAAU5FsAABgMqPG8MjhjoyMDFksFpfDZrP9X0yGoYyMDMXFxSk4OFg9evTQjh07XMZwOBwaP368oqKiFBoaqoEDB+rAgQNuf3+SDQAAzFbjocNNV199tYqLi53Htm3bnOdmzpypWbNmad68eSooKJDNZlPv3r119OhRZx+73a78/Hzl5eVpw4YNOnbsmPr376/q6mq34mDNBgAAJvPWo6/+/v4u1YxTDMPQ7NmzNW3aNN12222SpCVLligmJkYvv/yyxowZo8OHD2vRokVaunSpevXqJUlatmyZ4uPj9e6776pPnz51joPKBgAA9YTD4dCRI0dcDofDcdb+X331leLi4tSyZUvdeeed2r17tySpqKhIJSUlSktLc/a1Wq1KTU3Vxo0bJUmFhYWqrKx06RMXF6fExERnn7oi2QAAwGwemkbJyspSeHi4y5GVlXXGW3bp0kV///vf9c4772jhwoUqKSlRt27d9MMPP6ikpESSFBMT43JNTEyM81xJSYkCAwPVpEmTs/apK6ZRAAAwmeGhR1+nTp2qCRMmuLRZrdYz9u3bt6/zv5OSktS1a1e1bt1aS5Ys0XXXXSdJslgsrnEaRq2209Wlz+mobAAAUE9YrVaFhYW5HGdLNk4XGhqqpKQkffXVV851HKdXKEpLS53VDpvNpoqKCpWVlZ21T12RbAAAYDYvPY3ySw6HQzt37lRsbKxatmwpm82mtWvXOs9XVFRo/fr16tatmyQpJSVFAQEBLn2Ki4u1fft2Z5+6YhoFAACTeWoaxR2TJk3SgAED1KxZM5WWluovf/mLjhw5ohEjRshischutyszM1MJCQlKSEhQZmamQkJCNGzYMElSeHi40tPTNXHiREVGRioiIkKTJk1SUlKS8+mUuiLZAACgATpw4IDuuusuHTp0SE2bNtV1112njz/+WM2bN5ckTZ48WeXl5Ro7dqzKysrUpUsXrVmzRo0bN3aOkZOTI39/fw0ZMkTl5eXq2bOncnNz5efn51YsFsMwGtzbYSoP7fZ2CMBFKSSuu7dDAC46lRXfmn6PQ31SPTJO1DvrPTLOhUZlAwAAk3ljGuViQrIBAIDJfD3Z4GkUAABgKiobAACYzNcrGyQbAACYzXBvx82GhmkUAABgqt+cbFRXV2vr1q21tjMFAAAnGTWeOeort5MNu92uRYsWSTqZaKSmpqpDhw6Kj4/XBx984On4AACo94wai0eO+srtZOO1117TtddeK0l68803VVRUpP/85z+y2+2aNm2axwMEAAD1m9vJxqFDh5xvi1u1apXuuOMOXXnllUpPT9e2bds8HiAAAPUd0yhuiomJ0Zdffqnq6mqtXr3a+TKWEydOuL1XOgAAvsAwLB456iu3H3299957NWTIEMXGxspisah3796SpE8++URXXXWVxwMEAAD1m9vJRkZGhhITE7V//37dcccdslqtkiQ/Pz/98Y9/9HiAAADUd/V5CsQTeOsr4EN46ytQ24V46+v+Tj09Mk58wXseGedCq1NlY86cOXUe8OGHHz7vYAAAaIga3p/17qlTspGTk1OnwSwWC8kGAABwUadko6ioyOw4AABosOrzhlyecN7blVdUVGjXrl2qqqryZDwAADQ47CDqphMnTig9PV0hISG6+uqrtW/fPkkn12o8+eSTHg8QAADUb24nG1OnTtXnn3+uDz74QEFBQc72Xr166dVXX/VocAAANASG4ZmjvnJ7n40VK1bo1Vdf1XXXXSeL5f9KOu3atdM333zj0eAAAGgI6vMUiCe4Xdk4ePCgoqOja7UfP37cJfkAAACQziPZ6NSpk/71r385P59KMBYuXKiuXbt6LjIAABoI3o3ipqysLN1yyy368ssvVVVVpaefflo7duzQpk2btH79ejNiBACgXvP17crdrmx069ZNH330kU6cOKHWrVtrzZo1iomJ0aZNm5SSkmJGjAAAoB5zu7IhSUlJSVqyZImnYwEAoEGqqcdTIJ5wXslGdXW18vPztXPnTlksFrVt21aDBg2Sv/95DQcAQINWn9dbeILb2cH27ds1aNAglZSUqE2bNpKk//73v2ratKlWrlyppKQkjwcJAEB9xqOvbrrvvvt09dVX68CBA/rss8/02Wefaf/+/brmmmt0//33mxEjAACox9yubHz++efavHmzmjRp4mxr0qSJ/vrXv6pTp04eDQ4AgIagPu/+6QluVzbatGmj77//vlZ7aWmprrjiCo8EBQBAQ8KL2OrgyJEjziMzM1MPP/ywXnvtNR04cEAHDhzQa6+9JrvdruzsbLPjBQAA9YzFMH69uNOoUSOXrchPXXKq7Zefq6urzYjTLZWHdns7BOCiFBLX3dshABedyopvTb/H9lb9PTJO4u63PDLOhVanNRvr1q0zOw4AABosHn2tg9TUVLPjAAAADdR578J14sQJ7du3TxUVFS7t11xzzW8OCgCAhoSnUdx08OBB9e/fX40bN9bVV1+t5ORklwMAALiqMSweOX6LrKwsWSwW2e12Z5thGMrIyFBcXJyCg4PVo0cP7dixw+U6h8Oh8ePHKyoqSqGhoRo4cKAOHDjg1r3dTjbsdrvKysr08ccfKzg4WKtXr9aSJUuUkJCglStXujscAAAwWUFBgZ5//vlasw8zZ87UrFmzNG/ePBUUFMhms6l37946evSos4/dbld+fr7y8vK0YcMGHTt2TP3793frgRC3k433339fOTk56tSpkxo1aqTmzZvr7rvv1syZM5WVleXucAAANHiGYfHIcT6OHTum4cOHa+HChS4bchqGodmzZ2vatGm67bbblJiYqCVLlujEiRN6+eWXJUmHDx/WokWL9NRTT6lXr15KTk7WsmXLtG3bNr377rt1jsHtZOP48eOKjo6WJEVEROjgwYOSTr4J9rPPPnN3OAAAGjzD8MxxPsaNG6d+/fqpV69eLu1FRUUqKSlRWlqas81qtSo1NVUbN26UJBUWFqqystKlT1xcnBITE5196sLtBaJt2rTRrl271KJFC7Vv317PPfecWrRooQULFig2Ntbd4QAAaPA89Yp5h8Mhh8Ph0ma1WmW1Ws/YPy8vT5999pkKCgpqnSspKZEkxcTEuLTHxMRo7969zj6BgYEuFZFTfU5dXxfntWajuLhYkjR9+nStXr1azZo105w5c5SZmenucAAAoI6ysrIUHh7ucpxtCcP+/fv1yCOPaNmyZQoKCjrrmL/ctFM6Ob1yetvp6tLnl9yubAwfPtz538nJydqzZ4/+85//qFmzZoqKinJ3OFMEs0sicEZDYjt7OwTAJ3lqU6+pU6dqwoQJLm1nq2oUFhaqtLRUKSkpzrbq6mr9+9//1rx587Rr1y5JJ6sXv5yZKC0tdVY7bDabKioqVFZW5lLdKC0tVbdu3eoct9uVjdOFhISoQ4cOF02iAQDAxcZTj75arVaFhYW5HGdLNnr27Klt27Zp69atzqNjx44aPny4tm7dqlatWslms2nt2rXOayoqKrR+/XpnIpGSkqKAgACXPsXFxdq+fbtbyUadKhunZ1HnMmvWrDr3BQAA5mjcuLESExNd2kJDQxUZGelst9vtyszMVEJCghISEpSZmamQkBANGzZMkhQeHq709HRNnDhRkZGRioiI0KRJk5SUlFRrwem51CnZ2LJlS50Gc2f+BgAAX3GxbiA6efJklZeXa+zYsSorK1OXLl20Zs0aNW7c2NknJydH/v7+GjJkiMrLy9WzZ0/l5ubKz8+vzvep01tf6xv/wMu8HQJwUWLNBlDby3vzTb/HxtjfeWScbsWve2ScC+03r9kAAAA4l/N+ERsAAKgbXjEPAABMVePtALyMaRQAAGAqKhsAAJjMkG9Po5xXZWPp0qW6/vrrFRcX59w/ffbs2frnP//p0eAAAGgIagzPHPWV28nG/PnzNWHCBN1666366aefnO+zv/TSSzV79mxPxwcAQL1XI4tHjvrK7WRj7ty5WrhwoaZNm+ayoUfHjh21bds2jwYHAADqP7fXbBQVFSk5OblWu9Vq1fHjxz0SFAAADQlrNtzUsmVLbd26tVb722+/rXbt2nkiJgAAGpQaDx31lduVjUcffVTjxo3Tzz//LMMw9Omnn+qVV15RVlaWXnjhBTNiBAAA9Zjbyca9996rqqoqTZ48WSdOnNCwYcN02WWX6emnn9add95pRowAANRrvj6Ncl77bIwePVqjR4/WoUOHVFNTo+joaE/HBQBAg1Gfp0A84Tdt6hUVFeWpOAAAQAPldrLRsmVLWSxnLwft3r37NwUEAEBDQ2XDTXa73eVzZWWltmzZotWrV+vRRx/1VFwAADQYrNlw0yOPPHLG9meeeUabN2/+zQEBAICGxWNvfe3bt69ef/11Tw0HAECDUWPxzFFfeeytr6+99poiIiI8NRwAAA1GfX6viSe4nWwkJye7LBA1DEMlJSU6ePCgnn32WY8GBwBAQ1CPX9jqEW4nG4MHD3b53KhRIzVt2lQ9evTQVVdd5am4AABAA+FWslFVVaUWLVqoT58+stlsZsUEAECD4uuPvrq1QNTf318PPvigHA6HWfEAANDg1FgsHjnqK7efRunSpYu2bNliRiwAAKABcnvNxtixYzVx4kQdOHBAKSkpCg0NdTl/zTXXeCw4AAAaAhaI1tGoUaM0e/ZsDR06VJL08MMPO89ZLBYZhiGLxaLq6mrPRwkAQD3m62s26pxsLFmyRE8++aSKiorMjAcAADQwdU42DONkEah58+amBQMAQENUn3f/9AS31myc622vAADgzNhB1A1XXnnlryYcP/74428KCAAANCxuJRszZsxQeHi4WbEAANAg8TSKG+68805FR0ebFQsAAA0SazbqiPUaAACcH19/9LXOO4ieehoFAADAHXWubNTU+HpeBgDA+fH1P9fd3q4cAAC4x9fXbLj9IjYAAAB3kGwAAGCyGg8d7pg/f76uueYahYWFKSwsTF27dtXbb7/tPG8YhjIyMhQXF6fg4GD16NFDO3bscBnD4XBo/PjxioqKUmhoqAYOHKgDBw64/f1JNgAAMJk3ko3LL79cTz75pDZv3qzNmzfr5ptv1qBBg5wJxcyZMzVr1izNmzdPBQUFstls6t27t44ePeocw263Kz8/X3l5edqwYYOOHTum/v37u/3SVYvRAB8z8Q+8zNshABelIbGdvR0CcNF5eW++6fd47vK7PTLOmAPLftP1ERER+t///V+NGjVKcXFxstvtmjJliqSTVYyYmBhlZ2drzJgxOnz4sJo2baqlS5c63/j+3XffKT4+XqtWrVKfPn3qfF8qGwAAmMyweOZwOBw6cuSIy+FwOH71/tXV1crLy9Px48fVtWtXFRUVqaSkRGlpac4+VqtVqamp2rhxoySpsLBQlZWVLn3i4uKUmJjo7FNXJBsAAJjMU9MoWVlZCg8PdzmysrLOet9t27bpkksukdVq1QMPPKD8/Hy1a9dOJSUlkqSYmBiX/jExMc5zJSUlCgwMVJMmTc7ap6549BUAgHpi6tSpmjBhgkub1Wo9a/82bdpo69at+umnn/T6669rxIgRWr9+vfP86buDG4bxqzuG16XP6Ug2AAAwmae2xbRaredMLk4XGBioK664QpLUsWNHFRQU6Omnn3au0ygpKVFsbKyzf2lpqbPaYbPZVFFRobKyMpfqRmlpqbp16+ZW3EyjAABgMsNDx2+OwzDkcDjUsmVL2Ww2rV271nmuoqJC69evdyYSKSkpCggIcOlTXFys7du3u51sUNkAAMBk3thB9LHHHlPfvn0VHx+vo0ePKi8vTx988IFWr14ti8Uiu92uzMxMJSQkKCEhQZmZmQoJCdGwYcMkSeHh4UpPT9fEiRMVGRmpiIgITZo0SUlJSerVq5dbsZBsAADQAH3//ff6/e9/r+LiYoWHh+uaa67R6tWr1bt3b0nS5MmTVV5errFjx6qsrExdunTRmjVr1LhxY+cYOTk58vf315AhQ1ReXq6ePXsqNzdXfn5+bsXCPhuAD2GfDaC2C7HPRk4zz+yz8Yd9v22fDW+hsgEAgMl8/b3pLBAFAACmorIBAIDJGtx6BTeRbAAAYDJvPI1yMWEaBQAAmIrKBgAAJvP1BaIkGwAAmMzX12wwjQIAAExFZQMAAJPV+Hhtg2QDAACTsWYDAACYyrfrGqzZAAAAJqOyAQCAyZhGAQAApmIHUQAAABNR2QAAwGQ8+goAAEzl26kG0ygAAMBkVDYAADAZT6MAAABT+fqaDaZRAACAqahsAABgMt+ua5BsAABgOtZsAAAAU7FmAwAAwERUNgAAMJlv1zVINgAAMJ2vr9lgGgUAAJiKygYAACYzfHwihWQDAACTMY0CAABgIiobAACYzNf32SDZAADAZL6dajCNAgAATEZlAwAAkzGNAgAATOXrT6OQbAAAYDJf32eDNRsAADRAWVlZ6tSpkxo3bqzo6GgNHjxYu3btculjGIYyMjIUFxen4OBg9ejRQzt27HDp43A4NH78eEVFRSk0NFQDBw7UgQMH3Irlok429u/fr1GjRp2zj8Ph0JEjR1wOw/DtDBIAcHGp8dDhjvXr12vcuHH6+OOPtXbtWlVVVSktLU3Hjx939pk5c6ZmzZqlefPmqaCgQDabTb1799bRo0edfex2u/Lz85WXl6cNGzbo2LFj6t+/v6qrq+sci8W4iH8zf/755+rQocM5v1BGRoZmzJjh0mZpdIka+YWZHR5Q7wyJ7eztEICLzst7802/x70tfueRcRbvef28rz148KCio6O1fv163XjjjTIMQ3FxcbLb7ZoyZYqkk3/Ax8TEKDs7W2PGjNHhw4fVtGlTLV26VEOHDpUkfffdd4qPj9eqVavUp0+fOt3bq2s2Vq5cec7zu3fv/tUxpk6dqgkTJri0NYm86jfFBQDAxcjhcMjhcLi0Wa1WWa3WX7328OHDkqSIiAhJUlFRkUpKSpSWluYyVmpqqjZu3KgxY8aosLBQlZWVLn3i4uKUmJiojRs31o9kY/DgwbJYLOec9rBYLOcc40w/5F+7BgCAC8lTT6NkZWXVquZPnz5dGRkZ57zOMAxNmDBBN9xwgxITEyVJJSUlkqSYmBiXvjExMdq7d6+zT2BgoJo0aVKrz6nr68KrazZiY2P1+uuvq6am5ozHZ5995s3wAADwiBrD8MgxdepUHT582OWYOnXqr97/oYce0hdffKFXXnml1rnT/0A3DONX/2ivS59f8mqykZKScs6E4teqHgAA+BKr1aqwsDCX49emUMaPH6+VK1dq3bp1uvzyy53tNptNkmpVKEpLS53VDpvNpoqKCpWVlZ21T114Ndl49NFH1a1bt7Oev+KKK7Ru3boLGBEAAJ5neOhw656GoYceekhvvPGG3n//fbVs2dLlfMuWLWWz2bR27VpnW0VFhdavX+/83ZySkqKAgACXPsXFxdq+ffs5f3+fzqtrNrp3737O86GhoUpNTb1A0QAAYA5vbFc+btw4vfzyy/rnP/+pxo0bOysY4eHhCg4OlsVikd1uV2ZmphISEpSQkKDMzEyFhIRo2LBhzr7p6emaOHGiIiMjFRERoUmTJikpKUm9evWqcyzsIAoAQAM0f/58SVKPHj1c2hcvXqyRI0dKkiZPnqzy8nKNHTtWZWVl6tKli9asWaPGjRs7++fk5Mjf319DhgxReXm5evbsqdzcXPn5+dU5lot6n43z5R94mbdDAC5K7LMB1HYh9tm4q/lgj4zzyt4VHhnnQqOyAQCAyXgRGwAAMJWvv2L+on43CgAAqP+obAAAYDJff8U8yQYAACbz9TUbTKMAAABTUdkAAMBkDXCXCbeQbAAAYDKeRgEAADARlQ0AAEzm6wtESTYAADCZrz/6yjQKAAAwFZUNAABM5usLREk2AAAwGY++AgAAU/n6AlHWbAAAAFNR2QAAwGS+/jQKyQYAACbz9QWiTKMAAABTUdkAAMBkPI0CAABMxTQKAACAiahsAABgMp5GAQAApqrx8TUbTKMAAABTUdkAAMBkvl3XINkAAMB0vv40CskGAAAm8/VkgzUbAADAVFQ2AAAwGTuIAgAAUzGNAgAAYCIqGwAAmIwdRAEAgKl8fc0G0ygAAMBUVDYAADCZry8QJdkAAMBkTKMAAIAG6d///rcGDBiguLg4WSwWrVixwuW8YRjKyMhQXFycgoOD1aNHD+3YscOlj8Ph0Pjx4xUVFaXQ0FANHDhQBw4ccCsOkg0AAExWI8Mjh7uOHz+ua6+9VvPmzTvj+ZkzZ2rWrFmaN2+eCgoKZLPZ1Lt3bx09etTZx263Kz8/X3l5edqwYYOOHTum/v37q7q6us5xWIwGWNvxD7zM2yEAF6UhsZ29HQJw0Xl5b77p97jG1tUj43xRsum8r7VYLMrPz9fgwYMlnaxqxMXFyW63a8qUKZJOVjFiYmKUnZ2tMWPG6PDhw2ratKmWLl2qoUOHSpK+++47xcfHa9WqVerTp0+d7k1lAwAAk9UYhkcOh8OhI0eOuBwOh+O8YioqKlJJSYnS0tKcbVarVampqdq4caMkqbCwUJWVlS594uLilJiY6OxTFyQbAADUE1lZWQoPD3c5srKyzmuskpISSVJMTIxLe0xMjPNcSUmJAgMD1aRJk7P2qQueRgEAwGSe2kF06tSpmjBhgkub1Wr9TWNaLBaXz4Zh1Go7XV36/BLJBgAAJqvx0PJIq9X6m5OLU2w2m6ST1YvY2Fhne2lpqbPaYbPZVFFRobKyMpfqRmlpqbp161bnezGNAgCAD2rZsqVsNpvWrl3rbKuoqND69eudiURKSooCAgJc+hQXF2v79u1uJRtUNgAAMJm3XsR27Ngxff31187PRUVF2rp1qyIiItSsWTPZ7XZlZmYqISFBCQkJyszMVEhIiIYNGyZJCg8PV3p6uiZOnKjIyEhFRERo0qRJSkpKUq9eveocB8kGAAAm89Q0irs2b96sm266yfn51HqPESNGKDc3V5MnT1Z5ebnGjh2rsrIydenSRWvWrFHjxo2d1+Tk5Mjf319DhgxReXm5evbsqdzcXPn5+dU5DvbZAHwI+2wAtV2IfTaubNrRI+P89+Bmj4xzoVHZAADAZN6aRrlYkGwAAGAyb02jXCx4GgUAAJiKygYAACZjGgUAAJjKMGq8HYJXkWwAAGCy83k9fEPCmg0AAGAqKhsAAJisAW5p5RaSDQAATMY0CgAAgImobAAAYDKmUQAAgKnYQRQAAMBEVDYAADAZO4gCAABT+fqaDaZRAACAqahsAABgMl/fZ4NkAwAAk/n6NArJBgAAJuPRVwAAABNR2QAAwGRMowAAAFP5+gJRplEAAICpqGwAAGAyplEAAICpeBoFAADARFQ2AAAwGS9iAwAApmIaBQAAwERUNgAAMBlPowAAAFOxZgMAAJjK1ysbrNkAAACmorIBAIDJfL2yQbIBAIDJfDvVYBoFAACYzGL4em0HpnE4HMrKytLUqVNltVq9HQ5w0eDfBnwNyQZMc+TIEYWHh+vw4cMKCwvzdjjARYN/G/A1TKMAAABTkWwAAABTkWwAAABTkWzANFarVdOnT2cBHHAa/m3A17BAFAAAmIrKBgAAMBXJBgAAMBXJBgAAMBXJBgAAMBXJBkzz7LPPqmXLlgoKClJKSoo+/PBDb4cEeNW///1vDRgwQHFxcbJYLFqxYoW3QwIuCJINmOLVV1+V3W7XtGnTtGXLFnXv3l19+/bVvn37vB0a4DXHjx/Xtddeq3nz5nk7FOCC4tFXmKJLly7q0KGD5s+f72xr27atBg8erKysLC9GBlwcLBaL8vPzNXjwYG+HApiOygY8rqKiQoWFhUpLS3NpT0tL08aNG70UFQDAW0g24HGHDh1SdXW1YmJiXNpjYmJUUlLipagAAN5CsgHTWCwWl8+GYdRqAwA0fCQb8LioqCj5+fnVqmKUlpbWqnYAABo+kg14XGBgoFJSUrR27VqX9rVr16pbt25eigoA4C3+3g4ADdOECRP0+9//Xh07dlTXrl31/PPPa9++fXrggQe8HRrgNceOHdPXX3/t/FxUVKStW7cqIiJCzZo182JkgLl49BWmefbZZzVz5kwVFxcrMTFROTk5uvHGG70dFuA1H3zwgW666aZa7SNGjFBubu6FDwi4QEg2AACAqVizAQAATEWyAQAATEWyAQAATEWyAQAATEWyAQAATEWyAQAATEWyAQAATEWyAXhRRkaG2rdv7/w8cuRIDR48+ILHsWfPHlksFm3duvWsfVq0aKHZs2fXeczc3Fxdeumlvzk2i8WiFStW/OZxAHgPyQZwmpEjR8pischisSggIECtWrXSpEmTdPz4cdPv/fTTT9d5J8m6JAgAcDHg3SjAGdxyyy1avHixKisr9eGHH+q+++7T8ePHNX/+/Fp9KysrFRAQ4JH7hoeHe2QcALiYUNkAzsBqtcpmsyk+Pl7Dhg3T8OHDnaX8U1MfL774olq1aiWr1SrDMHT48GHdf//9io6OVlhYmG6++WZ9/vnnLuM++eSTiomJUePGjZWenq6ff/7Z5fzp0yg1NTXKzs7WFVdcIavVqmbNmumvf/2rJKlly5aSpOTkZFksFvXo0cN53eLFi9W2bVsFBQXpqquu0rPPPutyn08//VTJyckKCgpSx44dtWXLFrd/RrNmzVJSUpJCQ0MVHx+vsWPH6tixY7X6rVixQldeeaWCgoLUu3dv7d+/3+X8m2++qZSUFAUFBalVq1aaMWOGqqqqznjPiooKPfTQQ4qNjVVQUJBatGihrKwst2MHcGFR2QDqIDg4WJWVlc7PX3/9tZYvX67XX39dfn5+kqR+/fopIiJCq1atUnh4uJ577jn17NlT//3vfxUREaHly5dr+vTpeuaZZ9S9e3ctXbpUc+bMUatWrc5636lTp2rhwoXKycnRDTfcoOLiYv3nP/+RdDJh6Ny5s959911dffXVCgwMlCQtXLhQ06dP17x585ScnKwtW7Zo9OjRCg0N1YgRI3T8+HH1799fN998s5YtW6aioiI98sgjbv9MGjVqpDlz5qhFixYqKirS2LFjNXnyZJfE5sSJE/rrX/+qJUuWKDAwUGPHjtWdd96pjz76SJL0zjvv6O6779acOXPUvXt3ffPNN7r//vslSdOnT691zzlz5mjlypVavny5mjVrpv3799dKXgBchAwALkaMGGEMGjTI+fmTTz4xIiMjjSFDhhiGYRjTp083AgICjNLSUmef9957zwgLCzN+/vlnl7Fat25tPPfcc4ZhGEbXrl2NBx54wOV8ly5djGuvvfaM9z5y5IhhtVqNhQsXnjHOoqIiQ5KxZcsWl/b4+Hjj5Zdfdml74oknjK5duxqGYRjPPfecERERYRw/ftx5fv78+Wcc65eaN29u5OTknPX88uXLjcjISOfnxYsXG5KMjz/+2Nm2c+dOQ5LxySefGIZhGN27dzcyMzNdxlm6dKkRGxvr/CzJyM/PNwzDMMaPH2/cfPPNRk1NzVnjAHDxobIBnMFbb72lSy65RFVVVaqsrNSgQYM0d+5c5/nmzZuradOmzs+FhYU6duyYIiMjXcYpLy/XN998I0nauXOnHnjgAZfzXbt21bp1684Yw86dO+VwONSzZ886x33w4EHt379f6enpGj16tLO9qqrKuR5k586duvbaaxUSEuISh7vWrVunzMxMffnllzpy5Iiqqqr0888/6/jx4woNDZUk+fv7q2PHjs5rrrrqKl166aXauXOnOnfurMLCQhUUFDinhiSpurpaP//8s06cOOESo3Rymql3795q06aNbrnlFvXv319paWluxw7gwiLZAM7gpptu0vz58xUQEKC4uLhaC0BP/TI9paamRrGxsfrggw9qjXW+j38GBwe7fU1NTY2kk1MpXbp0cTl3arrHMIzziueX9u7dq1tvvVUPPPCAnnjiCUVERGjDhg1KT093mW6STj66erpTbTU1NZoxY4Zuu+22Wn2CgoJqtXXo0EFFRUV6++239e6772rIkCHq1auXXnvttd/8nQCYh2QDOIPQ0FBdccUVde7foUMHlZSUyN/fXy1atDhjn7Zt2+rjjz/WPffc42z7+OOPzzpmQkKCgoOD9d577+m+++6rdf7UGo3q6mpnW0xMjC677DLt3r1bw4cPP+O47dq109KlS1VeXu5MaM4Vx5ls3rxZVVVVeuqpp9So0cl15suXL6/Vr6qqSps3b1bnzp0lSbt27dJPP/2kq666StLJn9uuXbvc+lmHhYVp6NChGjp0qG6//Xbdcsst+vHHHxUREeHWdwBw4ZBsAB7Qq1cvde3aVYMHD1Z2drbatGmj7777TqtWrdLgwYPVsWNHPfLIIxoxYoQ6duyoG264QS+99JJ27Nhx1gWiQUFBmjJliiZPnqzAwEBdf/31OnjwoHbs2KH09HRFR0crODhYq1ev1uWXX66goCCFh4crIyNDDz/8sMLCwtS3b185HA5t3rxZZWVlmjBhgoYNG6Zp06YpPT1d//M//6M9e/bob3/7m1vft3Xr1qqqqtLcuXM1YMAAffTRR1qwYEGtfgEBARo/frzmzJmjgIAAPfTQQ7ruuuucycfjjz+u/v37Kz4+XnfccYcaNWqkL774Qtu2bdNf/vKXWuPl5OQoNjZW7du3V6NGjfSPf/xDNpvNI5uHATAPj74CHmCxWLRq1SrdeOONGjVqlK688krdeeed2rNnj2JiYiRJQ4cO1eOPP64pU6YoJSVFe/fu1YMPPnjOcf/0pz9p4sSJevzxx9W2bVsNHTpUpaWlkk6uh5gzZ46ee+45xcXFadCgQZKk++67Ty+88IJyc3OVlJSk1NRU5ebmOh+VveSSS/Tmm2/qyy+/VHJysqZNm6bs7Gy3vm/79u01a9YsZWdnKzExUS+99NIZH0ENCQnRlClTNGzYMHXt2lXBwcHKy8tznu/Tp4/eeustrV27Vp06ddJ1112nWbNmqXnz5me87yWXXKLs7Gx17NhRnTp10p49e7Rq1SpndQXAxclieGICFwAA4Cz4cwAAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJiKZAMAAJjq/wMu3+RXBpVlkAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(class_true, class_predict)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy = (741+139)/(741+139+11+19) = 0.967 = 0.97, matching the classification report\n",
    "\n",
    "Class 0:\n",
    "- Recall = 0.99\n",
    "- Precision = 0.97\n",
    "\n",
    "Class 1:\n",
    "- Recall = 0.88\n",
    "- Precision = 0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Report how often your model encountered out-of-vocabulary words in the test set. Were any test items skipped (not classified) due to this problem?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trouble': 1, '2nite': 5, 'hmv': 1, 'law': 2, 'plot': 1, 'pie': 3, 'drivin': 3, 'realise': 1, 'hook': 3, 'nearly': 1, 'fetch': 1, 'activity': 2, 'inside': 3, 'greet': 1, 'grl': 1, 'manage': 2, '87131': 1, 'journey': 1, 'require': 2, '://': 3, 'daddy': 4, 'asleep': 4, 'market': 2, 'depend': 1, 'prabha': 1, 'wed': 2, 'title': 1, 'piece': 1, 'fault': 3, 'lift': 2, 'girlfrnd': 1, 'boston': 2, 'nyc': 2, 't-mobile': 3, '0845': 2, 'skype': 2, 'mini': 2, 'postcode': 1, 'dreams': 3, 'lmao': 2, 'armand': 1, '1956669': 2, 'possession': 2, 'feelin': 1, 'befor': 1, 'ru': 1, 'sen': 1, 'fire': 1, 'definitely': 1, 'legal': 2, 'holla': 3, 'sup': 1, 'dick': 2, 'harry': 1, 'oz': 3, 'yijue': 1, 'exactly': 2, 'bet': 1, 'esplanade': 2, 'bud': 1, 'din': 2, 'act': 3, '=d': 1, 'challenge': 1, 'wet': 1, '6hrs': 3, '7250i': 1, '0578': 2, 'annoying': 2, 'calling': 3, 'rally': 2, 'pack': 1, 'empty': 3, 'fyi': 2, '81151': 1, 'report': 1, 'gram': 1, 'lay': 2, 'yahoo': 1, 'experience': 2, 'fee': 1, 'k.': 2, 'pg': 1, 'ec2a': 1, 'woke': 2, 'realy': 1, 'lecture': 1, 'cancer': 1, 'fromm': 1, 'aiyar': 1, 'ta': 1, '32': 1, 'infernal': 1, 'affair': 1}\n",
      "Number of unique tokens not classifed = 94\n",
      "Number of instances model encountered out-of-vocab during testing = 160\n"
     ]
    }
   ],
   "source": [
    "test_out_of_vocab = dict()\n",
    "for i in range(len(test)):\n",
    "    text = test.loc[i, \"textPreprocessed\"]\n",
    "    text_tokens = return_tokens(text)\n",
    "    tokens_out_of_vocab = 0\n",
    "\n",
    "    for token in text_tokens:\n",
    "        if token not in vocabulary:\n",
    "            tokens_out_of_vocab += 1\n",
    "            if token not in test_out_of_vocab.keys():\n",
    "                test_out_of_vocab[token] = 1\n",
    "            else:\n",
    "                test_out_of_vocab[token] += 1\n",
    "\n",
    "print(test_out_of_vocab)\n",
    "print(f\"Number of unique tokens not classifed = {len(test_out_of_vocab)}\")\n",
    "print(f\"Number of instances model encountered out-of-vocab during testing = {sum(test_out_of_vocab.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 test instances skipped\n"
     ]
    }
   ],
   "source": [
    "num_tests_skipped = len(test[test[\"predicted class\"].isna()])\n",
    "print(f\"There were {num_tests_skipped} test instances skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Provide examples of instances classified with high low confidence using ratio of posterior likelihood for each class. Provide some examples of test instances which are:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. classified scam (label=1) with high confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: . 4 + call £ - * holiday & urgent 18 t landline 150ppm cash cs await collection po box sae complimentary 10,000 ibiza\n",
      "R score: 1.3538895972838257e+20\n",
      "\n",
      "2.\n",
      "Text: . 3 4 + ! call : £ offer * holiday & urgent 18 t landline 150ppm cash cs await collection po box sae tenerife 10,000\n",
      "R score: 1.2870905388142915e+20\n",
      "\n",
      "3.\n",
      "Text: . . . , please order text call / : customer tone number [ [ service mobile ] ] colour colour thanks ringtone reference charge 4.50 arrive = red x49 09065989182\n",
      "R score: 1.1491239652938205e+20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=1, c2=0)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. classified non-malicious (label=0) with high confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: time : rs. transaction number & & & & & & & & & & ; ; ; ; ; ; ; ; ; ; lt lt lt lt lt # # # gt gt gt gt gt credit account reference decimal\n",
      "R score: 9.134994451628885e+37\n",
      "\n",
      "2.\n",
      "Text: ? ? ? ? .. .. u u u u , , ... ... ... ... say person yes ! f : hello hello hello o o wen knw knw girl girl mean @ \" \" \" \" t name name g g n d d d d d d lift bt real dat h girlfrnd girlfrnd moral\n",
      "R score: 2.690381858561345e+29\n",
      "\n",
      "3.\n",
      "Text: . every & & & & & & ; ; ; ; ; ; lt lt lt # # # gt gt gt big hr\n",
      "R score: 3.182924541185372e+25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=0, c2=1)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. on the boundary between the 2 classes (R near 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: . call dear\n",
      "R score: 0.9831892964622647\n",
      "\n",
      "2.\n",
      "Text: . reply glad\n",
      "R score: 0.9577512241887175\n",
      "\n",
      "3.\n",
      "Text: . . tell return re order\n",
      "R score: 1.0755396179747467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=1, c2=0, boundary=True)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: . call dear\n",
      "R score: 1.0170981352199664\n",
      "\n",
      "2.\n",
      "Text: . reply glad\n",
      "R score: 1.0441124738285459\n",
      "\n",
      "3.\n",
      "Text: . . tell return re order\n",
      "R score: 0.929765843384748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=0, c2=1, boundary=True)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here, we should expect to receive the same texts regardless of what c1 or c2 is, which is true, as shown in results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition to reporting these points, briefly interpret them. Do the model’s high and low confidence\n",
    "predictions seem reasonable to you? Is one class easier to identify than the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well, having high accuracy and recall/precision per class in the test set. Looking at both recall and precision factors, i.e., the f1 score, the model performs better at predicting non-malicious texts (0.98), compared to scam texts (0.90). The difference may be due to class imbalance in the training set (80/20), where non malicious texts appear more than scams. Because of less occurances of scam instances, the model might not be as well trained on the minority class where there are less examples.\n",
    "\n",
    "The model's predictive capability can be further improved by having larger training datasets which reduce the number of unique tokens that cannot be identified in the test dataset. Fortunately, this issue did not lead to any non-classifications/skips in testing.\n",
    "\n",
    "Additionally, the model's confidence values seem reasonable. The top 3 results in the scam predictions have extremely high confidence, and the contents of the texts reflect this confidence value, tokens such as \"claim\", \"discount\", \"offer\", \"cash\"... are indicative of scam attempts. \n",
    "While there is also high confidence in non-malicious predictions, the degree/magnitude of confidence in scam instances is much higher, where the highest R score of label=0 is approx  3,500,000, compared to approx 1.22E12 in the scam class, almost a million times larger (looking at the number of extra 0s).\n",
    "\n",
    "In summary, based on f1, the model performs better when predicting non-malicious texts, however, looking at confidence, the model is more confident in the scam class, possibly due to more pronounced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extending the model with semi-supervised training - Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set by splitting train dataset into train/validation subset\n",
    "train = pd.read_csv(\"sms_supervised_train.csv\")\n",
    "train_data, validation_data = train_test_split(train, test_size=0.2, random_state=1, stratify=train['class'])\n",
    "\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "validation_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give her something to drink, if she takes it a...</td>\n",
       "      <td>. . , know take may let give vomit something d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In other news after hassling me to get him wee...</td>\n",
       "      <td>. get week news weed money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's just gonna worry for nothing. And he won'...</td>\n",
       "      <td>. . go he 's just give to nothing worry money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm nt goin, got somethin on, unless they meet...</td>\n",
       "      <td>4 , , , get lor go ... ... time goin haha unle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tell my  bad character which u Dnt lik in me. ...</td>\n",
       "      <td>. . . . . 2 character reply u ll ur ... year g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>\\tWe tried to call you re your reply to our sm...</td>\n",
       "      <td>reply reply free re sm text call call 750 try ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>This phone has the weirdest auto correct.</td>\n",
       "      <td>. phone correct weird</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>We'll join the  &amp;lt;#&amp;gt;  bus</td>\n",
       "      <td>&amp; &amp; ; ; lt # gt join bus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Great! I hope you like your man well endowed. ...</td>\n",
       "      <td>. great hope like ... man ! well &amp; &amp; ; ; lt # ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Babe ? I lost you ... Will you try rebooting ?</td>\n",
       "      <td>? ? ... try babe lose</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           textOriginal  \\\n",
       "0     Give her something to drink, if she takes it a...   \n",
       "1     In other news after hassling me to get him wee...   \n",
       "2     He's just gonna worry for nothing. And he won'...   \n",
       "3     I'm nt goin, got somethin on, unless they meet...   \n",
       "4     Tell my  bad character which u Dnt lik in me. ...   \n",
       "...                                                 ...   \n",
       "1595  \\tWe tried to call you re your reply to our sm...   \n",
       "1596          This phone has the weirdest auto correct.   \n",
       "1597                     We'll join the  &lt;#&gt;  bus   \n",
       "1598  Great! I hope you like your man well endowed. ...   \n",
       "1599     Babe ? I lost you ... Will you try rebooting ?   \n",
       "\n",
       "                                       textPreprocessed  class  \n",
       "0     . . , know take may let give vomit something d...      0  \n",
       "1                            . get week news weed money      0  \n",
       "2         . . go he 's just give to nothing worry money      0  \n",
       "3     4 , , , get lor go ... ... time goin haha unle...      0  \n",
       "4     . . . . . 2 character reply u ll ur ... year g...      0  \n",
       "...                                                 ...    ...  \n",
       "1595  reply reply free re sm text call call 750 try ...      1  \n",
       "1596                              . phone correct weird      0  \n",
       "1597                           & & ; ; lt # gt join bus      0  \n",
       "1598  . great hope like ... man ! well & & ; ; lt # ...      0  \n",
       "1599                              ? ? ... try babe lose      0  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m count_matrix \u001b[38;5;241m=\u001b[39m find_count_matrix(train_data, vocabulary)\n\u001b[0;32m      4\u001b[0m prior_probs \u001b[38;5;241m=\u001b[39m find_prior_prob(train_data)\n\u001b[1;32m----> 5\u001b[0m conditional_probs \u001b[38;5;241m=\u001b[39m \u001b[43mfind_conditional_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[131], line 10\u001b[0m, in \u001b[0;36mfind_conditional_prob\u001b[1;34m(data, vocabulary, count_matrix)\u001b[0m\n\u001b[0;32m      7\u001b[0m     conditional_probs[label] \u001b[38;5;241m=\u001b[39m {word: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m vocabulary}\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m vocabulary:\n\u001b[1;32m---> 10\u001b[0m         conditional_probs[label][word] \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_p_c_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conditional_probs\n",
      "Cell \u001b[1;32mIn[130], line 12\u001b[0m, in \u001b[0;36mcalc_p_c_i\u001b[1;34m(data, count_matrix, label, word, V, alpha)\u001b[0m\n\u001b[0;32m     10\u001b[0m count_matrix \u001b[38;5;241m=\u001b[39m count_matrix\u001b[38;5;241m.\u001b[39miloc[label_indexes]\n\u001b[0;32m     11\u001b[0m word_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(count_matrix[word]) \u001b[38;5;241m+\u001b[39m alpha\n\u001b[1;32m---> 12\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m (V\u001b[38;5;241m*\u001b[39malpha)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(word_counts \u001b[38;5;241m/\u001b[39m label_counts)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11312\u001b[0m, in \u001b[0;36mDataFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11303\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  11305\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11310\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11311\u001b[0m ):\n\u001b[1;32m> 11312\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12078\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12070\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  12071\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12072\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12077\u001b[0m ):\n\u001b[1;32m> 12078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_count_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12079\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  12080\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12061\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m  12059\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m> 12061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12064\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12068\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11204\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11200\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11202\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11203\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11204\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11205\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11136\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:85\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduction operation \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not allowed for this dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:477\u001b[0m, in \u001b[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001b[1;34m(values, axis, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m         results \u001b[38;5;241m=\u001b[39m [func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrs]\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(results)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:639\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;124;03mSum the elements along an axis ignoring NaNs\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m3.0\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    638\u001b[0m dtype \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 639\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m \u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m dtype_sum \u001b[38;5;241m=\u001b[39m _get_dtype_max(dtype)\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:294\u001b[0m, in \u001b[0;36m_get_values\u001b[1;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03mUtility to get the values view, mask, dtype, dtype_max, and fill_value.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    Mask for values, if deemed necessary to compute\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# In _get_values is only called from within nanops, and in all cases\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m#  with scalar fill_value.  This guarantee is important for the\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m#  np.where call below\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_get_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m dtype \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    298\u001b[0m datetimelike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:248\u001b[0m, in \u001b[0;36m_maybe_get_mask\u001b[1;34m(values, skipna, mask)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skipna \u001b[38;5;129;01mor\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 248\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    298\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misfinite(values)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model only on train_data\n",
    "vocabulary = find_vocabulary(train_data)\n",
    "count_matrix = find_count_matrix(train_data, vocabulary)\n",
    "prior_probs = find_prior_prob(train_data)\n",
    "conditional_probs = find_conditional_prob(train_data, vocabulary, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the unsupervised dataset\n",
    "unlabelled = pd.read_csv(\"sms_unlabelled.csv\")\n",
    "unlabelled_instances = unlabelled[\"textPreprocessed\"]\n",
    "predicted_labels = []\n",
    "for unlabelled_instance in unlabelled_instances:\n",
    "    predicted_label = classify_test_instance(unlabelled, vocabulary, unlabelled_instance, prior_probs, conditional_probs)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "unlabelled[\"predicted class\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>. . . � home home please stay stay citizen ent...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BankOfAmerica Alert 137943. Please follow http...</td>\n",
       "      <td>. please alert follow re-activate</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry dude. Dont know how i forgot. Even after...</td>\n",
       "      <td>. . . . . sorry sorry dude know forget even re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. I dont want to hear anything</td>\n",
       "      <td>. hear anything</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Kay... Since we are out already</td>\n",
       "      <td>already ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>call now 08707509020 Just 20p per min NTT Ltd...</td>\n",
       "      <td>, call call just rate national per 0870 min 08...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Are you angry with me. What happen dear</td>\n",
       "      <td>. angry dear happen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>We r outside already.</td>\n",
       "      <td>. already r outside</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The Xmas story is peace.. The Xmas msg is love...</td>\n",
       "      <td>.. .. .. u ... story month love &amp; amp ; msg wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           textOriginal  \\\n",
       "0     Your opinion about me? 1. Over 2. Jada 3. Kusr...   \n",
       "1     Please Stay At Home. To encourage the notion o...   \n",
       "2     BankOfAmerica Alert 137943. Please follow http...   \n",
       "3     Sorry dude. Dont know how i forgot. Even after...   \n",
       "4                      No. I dont want to hear anything   \n",
       "...                                                 ...   \n",
       "1995                    Kay... Since we are out already   \n",
       "1996   call now 08707509020 Just 20p per min NTT Ltd...   \n",
       "1997            Are you angry with me. What happen dear   \n",
       "1998                              We r outside already.   \n",
       "1999  The Xmas story is peace.. The Xmas msg is love...   \n",
       "\n",
       "                                       textPreprocessed  class  \\\n",
       "0     opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...      0   \n",
       "1     . . . � home home please stay stay citizen ent...      1   \n",
       "2                     . please alert follow re-activate      1   \n",
       "3     . . . . . sorry sorry dude know forget even re...      0   \n",
       "4                                       . hear anything      0   \n",
       "...                                                 ...    ...   \n",
       "1995                                        already ...      0   \n",
       "1996  , call call just rate national per 0870 min 08...      1   \n",
       "1997                                . angry dear happen      0   \n",
       "1998                                . already r outside      0   \n",
       "1999  .. .. .. u ... story month love & amp ; msg wi...      0   \n",
       "\n",
       "      predicted class  \n",
       "0                 0.0  \n",
       "1                 1.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "1995              0.0  \n",
       "1996              1.0  \n",
       "1997              0.0  \n",
       "1998              0.0  \n",
       "1999              0.0  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ALRITE</td>\n",
       "      <td>alrite</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    textOriginal textPreprocessed  class  predicted class\n",
       "113       ALRITE           alrite      0              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>. . . � home home please stay stay citizen ent...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BankOfAmerica Alert 137943. Please follow http...</td>\n",
       "      <td>. please alert follow re-activate</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry dude. Dont know how i forgot. Even after...</td>\n",
       "      <td>. . . . . sorry sorry dude know forget even re...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. I dont want to hear anything</td>\n",
       "      <td>. hear anything</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        textOriginal  \\\n",
       "0  Your opinion about me? 1. Over 2. Jada 3. Kusr...   \n",
       "1  Please Stay At Home. To encourage the notion o...   \n",
       "2  BankOfAmerica Alert 137943. Please follow http...   \n",
       "3  Sorry dude. Dont know how i forgot. Even after...   \n",
       "4                   No. I dont want to hear anything   \n",
       "\n",
       "                                    textPreprocessed  class  \n",
       "0  opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...    0.0  \n",
       "1  . . . � home home please stay stay citizen ent...    1.0  \n",
       "2                  . please alert follow re-activate    1.0  \n",
       "3  . . . . . sorry sorry dude know forget even re...    0.0  \n",
       "4                                    . hear anything    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop any instances that can not be classified because none of its tokens appeared in vocabulary\n",
    "display(unlabelled)\n",
    "display(unlabelled[unlabelled[\"predicted class\"].isna()])\n",
    "unlabelled.dropna(subset=[\"predicted class\"], inplace=True)\n",
    "unlabelled = unlabelled[[\"textOriginal\", \"textPreprocessed\", \"predicted class\"]]\n",
    "unlabelled.rename(columns={\"predicted class\": \"class\"}, inplace=True)\n",
    "display(unlabelled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model on train_data + unlabelled data, do not touch validation set\n",
    "expanded_data = pd.concat([train_data, unlabelled], axis=0)\n",
    "expanded_data.reset_index(inplace=True, drop=False)\n",
    "vocabulary = find_vocabulary(expanded_data)\n",
    "count_matrix = find_count_matrix(expanded_data, vocabulary)\n",
    "prior_probs = find_prior_prob(expanded_data)\n",
    "conditional_probs = find_conditional_prob(expanded_data, vocabulary, count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Is it better to use all of the unlabelled data as described above, or only the instances that the Q1 model could label with high confidence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data):\n",
    "    vocabulary = find_vocabulary(data)\n",
    "    count_matrix = find_count_matrix(data, vocabulary)\n",
    "    prior_probs = find_prior_prob(data)\n",
    "    conditional_probs = find_conditional_prob(data, vocabulary, count_matrix)\n",
    "\n",
    "    return {\"data\": data,\n",
    "            \"vocabulary\": vocabulary,\n",
    "            \"count_matrix\": count_matrix,\n",
    "            \"prior_probs\": prior_probs,\n",
    "            \"conditional_probs\": conditional_probs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_confident_instances(model, unlabelled, conf=1):\n",
    "    data = model[\"data\"]\n",
    "    vocabulary = model[\"vocabulary\"]\n",
    "    count_matrix = model[\"count_matrix\"]\n",
    "    prior_probs = model[\"prior_probs\"]\n",
    "    conditional_probs = model[\"conditional_probs\"]\n",
    "\n",
    "    # Find R scores for each of the unlabelled instances\n",
    "\n",
    "    # Confidence of scam \n",
    "    scam_confidence = find_top_test_ratios(unlabelled, vocabulary, prior_probs, conditional_probs, c1=1, c2=0, top=len(unlabelled))\n",
    "    # Confidence of non-malicious\n",
    "    non_mal_confidence = find_top_test_ratios(unlabelled, vocabulary, prior_probs, conditional_probs, c1=0, c2=1, top=len(unlabelled))\n",
    "    \n",
    "    return scam_confidence, non_mal_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = create_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scam_confidence, non_mal_confidence = get_top_confident_instances(train_model, unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'. call £ £ guarantee won customer prize prize claim service 1000 10p yr 2000 representative cash 10am-7pm cost': 3.062234680601251e+20,\n",
       " ', ! ! ! ! call win £ * * * * * * * * * * * * * * * prize number 2nd urgent bonus mobile 2000 caller 150ppm attempt reach asap box': 1.906834375497819e+19,\n",
       " '. . please call £ apply end 350 todays voda number select receive match 08712300220 quoting claim code standard rate reward': 1.8895283672992813e+19,\n",
       " '. please call award apply end rs. vodafone todays number select receive match quoting claim code standard rate 2,00,000 7679046492': 1.81911444193788e+19,\n",
       " '. please call award apply end rs. vodafone todays number select receive match quoting claim code standard rate 2,00,000 8927307655': 9.0955722096894e+18,\n",
       " '2 2 4 u speak + ( ( ) ) / £ * select receive claim inc holiday 1000 18 live min winner specially operator flight': 8.643881123545552e+18,\n",
       " '1 2 3 week ! ) ) ) f : new download tone tone ready > > > > > > > > > info n weekly black p crazy include': 6.683733065279842e+18,\n",
       " '2 2 4 u u r speak ( ( ) ) / £ * select receive claim inc ave holiday 1000 18 live min winner cash specially operator flight': 6.018061946896724e+18,\n",
       " '. . ! call win £ show prize prize todays try contact land line u. draw draw 2000 guaranteed valid 12hrs xmas': 4.3907801898421647e+18,\n",
       " '2 free ur r award £ £ txt & & 500 100 cd gift voucher entry weekly draw music 87066 xmas': 3.329539358389575e+18,\n",
       " '. 4 free get ur ur week week tell + ! 1st / every txt just tone tone mate 16 mobile nokia nokia pobox www.getzed.co.uk no1 txting 36504 w45wq norm150p': 2.1475294797306307e+18,\n",
       " '. please call award end 350 todays voda number select receive match 08712300220 quoting claim code standard rate app $': 1.8849376618764216e+18,\n",
       " '4 get ur ur week tell + / every txt just tone tone mate 16 mob 8007 nokia nokia pobox www.getzed.co.uk no1 txting 36504 w45wq norm150p': 1.278181348776028e+18,\n",
       " '. ! call award win £ prize number claim urgent land line mobile 2000 150ppm guaranteed 3030 valid 12hrs': 1.1622301762817956e+18,\n",
       " '. . . ! call win £ show prize todays claim urgent try contact land line u. draw 2000 guaranteed 3030 valid 12hrs': 9.015341030053252e+17,\n",
       " ', ! ! ! ! call win £ * * * * * * * * * * * prize 2nd urgent bonus mobile caller 150ppm attempt reach 2,000 02/06/03 asap': 3.652292290510007e+17,\n",
       " '. . . . . 4 please + ! call £ * holiday & urgent t 16 landline 150ppm cash cs await collection po box 5000 island sae': 3.3308045647749e+17,\n",
       " '2 free even ur stop + ( ) call award award win £ £ 200 guarantee claim 1000 18': 3.222710609159282e+17,\n",
       " '. . . ! call win £ show prize todays claim urgent try contact land line 800 u. draw guaranteed valid 12hrs': 2.7574918993311286e+17,\n",
       " '. . . , please order text call / : customer tone number [ [ service mobile ] ] colour colour thanks ringtone reference charge 4.50 arrive = red x49 09065989182': 1.5408507054990195e+17,\n",
       " '. . . . . , weekend ! call show rs. customer prize claim code urgent try last contact dear draw guaranteed valid 12hrs fl1pkart w0n 5,00,000 7044518857': 1.4372562184674955e+17,\n",
       " '. . . ! ! ! call £ value customer prize select claim claim code hour network valid winner 900 reward 12': 1.1400127406716894e+17,\n",
       " 'u weekend call win £ show prize claim code pm urgent try last 150p 1000 contact draw guaranteed valid 12hrs k52': 1.0305821550756218e+17,\n",
       " 'please ! call £ £ guarantee won customer prize service 0800 1000 representative 10am-9pm cash 5000': 7.171951222480286e+16,\n",
       " '. . 2 2 4 free week 1st win £ every wk txt & chance 250 entry 08712405020 cash ts cs custcare 40gb ipod www.textpod.net 81303': 5.577180485459149e+16,\n",
       " '. . call award award £ £ end vodafone 350 350 todays number number select receive receive match': 5.502127297597983e+16,\n",
       " '2 free ur award txt guarantee & 500 100 congratulation cd voucher entry draw music 87066 tncs wkly': 5.466870980748191e+16,\n",
       " '. . . ! call award £ prize number claim urgent land line mobile 2000 150ppm guaranteed 3030 valid 12hrs': 5.318580270401679e+16,\n",
       " '. . . . . , weekend ! call show rs. customer prize claim code urgent try last contact dear draw guaranteed valid 12hrs fl1pkart w0n 8536074310 k52': 4.790854061558315e+16,\n",
       " '. . . ! call award prize number claim urgent < > mobile 2000 landline 150ppm guaranteed 3030 valid 12hrs': 4.473572190057488e+16}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\". . 4 u u , , , , , , , , ... year good 's new & & & amp ; ; ; day day day day day day lt # gt morning father happy happy happy happy happy happy happy happy happy happy happy happy happy happy happy u. jan fast wish wish valentines friendship mother teacher birthday christmas afternoon first\": 6.484102529862571e+33,\n",
       " '. . . . . 2 u u u , send send get like ... ... good person break break news & & & & ; ; ; ; tomorrow day lt lt # # gt gt problem life friday d min gud gud frnds dis pple dat hav lover read wil marry': 5.5879485819944075e+32,\n",
       " '. . . . . . . . . . . . . . . .. .. up up come thing thing get anyone anyone like late tell say lady time time every every every every take end end feel love love love love love ready girl day day morning dream need thank give thought always life life life name happen first beautiful beautiful start start start around around god fight cry whole lot crazy happiness': 1.0675478207016377e+31,\n",
       " '.. .. .. .. u u u , , , dude get il wen & & & & & & ; ; ; ; ; ; lt lt lt # # # gt gt gt credit mail draw y frnds rs rs rs money wit link thts member acc vl': 4.634715861496406e+30,\n",
       " '. , , , e text time & & & & & & ; ; ; ; ; ; tomorrow lt lt lt # # gt gt gt check again g st double': 2.3157857204390384e+27}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(unlabelled))\n",
    "display(len(scam_confidence))\n",
    "display(len(non_mal_confidence))\n",
    "display(dict(sorted(scam_confidence.items(), key=lambda x: x[1], reverse=True)[:30]))\n",
    "display(dict(sorted(non_mal_confidence.items(), key=lambda x: x[1], reverse=True)[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>Scam confidence</th>\n",
       "      <th>Non-malicious confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.014906e-04</td>\n",
       "      <td>4.963010e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>. . . � home home please stay stay citizen ent...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.264532e+00</td>\n",
       "      <td>7.908066e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BankOfAmerica Alert 137943. Please follow http...</td>\n",
       "      <td>. please alert follow re-activate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.289955e+01</td>\n",
       "      <td>1.589837e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry dude. Dont know how i forgot. Even after...</td>\n",
       "      <td>. . . . . sorry sorry dude know forget even re...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.659360e-08</td>\n",
       "      <td>3.760304e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. I dont want to hear anything</td>\n",
       "      <td>. hear anything</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031944e-02</td>\n",
       "      <td>9.690453e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Kay... Since we are out already</td>\n",
       "      <td>already ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.059396e-04</td>\n",
       "      <td>2.463421e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>call now 08707509020 Just 20p per min NTT Ltd...</td>\n",
       "      <td>, call call just rate national per 0870 min 08...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.422397e+12</td>\n",
       "      <td>1.061301e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Are you angry with me. What happen dear</td>\n",
       "      <td>. angry dear happen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.030894e-02</td>\n",
       "      <td>9.700318e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>We r outside already.</td>\n",
       "      <td>. already r outside</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.387732e-03</td>\n",
       "      <td>4.188074e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The Xmas story is peace.. The Xmas msg is love...</td>\n",
       "      <td>.. .. .. u ... story month love &amp; amp ; msg wi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399660e-09</td>\n",
       "      <td>7.144591e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           textOriginal  \\\n",
       "0     Your opinion about me? 1. Over 2. Jada 3. Kusr...   \n",
       "1     Please Stay At Home. To encourage the notion o...   \n",
       "2     BankOfAmerica Alert 137943. Please follow http...   \n",
       "3     Sorry dude. Dont know how i forgot. Even after...   \n",
       "4                      No. I dont want to hear anything   \n",
       "...                                                 ...   \n",
       "1995                    Kay... Since we are out already   \n",
       "1996   call now 08707509020 Just 20p per min NTT Ltd...   \n",
       "1997            Are you angry with me. What happen dear   \n",
       "1998                              We r outside already.   \n",
       "1999  The Xmas story is peace.. The Xmas msg is love...   \n",
       "\n",
       "                                       textPreprocessed  class  \\\n",
       "0     opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...    0.0   \n",
       "1     . . . � home home please stay stay citizen ent...    1.0   \n",
       "2                     . please alert follow re-activate    1.0   \n",
       "3     . . . . . sorry sorry dude know forget even re...    0.0   \n",
       "4                                       . hear anything    0.0   \n",
       "...                                                 ...    ...   \n",
       "1995                                        already ...    0.0   \n",
       "1996  , call call just rate national per 0870 min 08...    1.0   \n",
       "1997                                . angry dear happen    0.0   \n",
       "1998                                . already r outside    0.0   \n",
       "1999  .. .. .. u ... story month love & amp ; msg wi...    0.0   \n",
       "\n",
       "      Scam confidence  Non-malicious confidence  \n",
       "0        2.014906e-04              4.963010e+03  \n",
       "1        1.264532e+00              7.908066e-01  \n",
       "2        6.289955e+01              1.589837e-02  \n",
       "3        2.659360e-08              3.760304e+07  \n",
       "4        1.031944e-02              9.690453e+01  \n",
       "...               ...                       ...  \n",
       "1995     4.059396e-04              2.463421e+03  \n",
       "1996     9.422397e+12              1.061301e-13  \n",
       "1997     1.030894e-02              9.700318e+01  \n",
       "1998     2.387732e-03              4.188074e+02  \n",
       "1999     1.399660e-09              7.144591e+08  \n",
       "\n",
       "[1999 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled[\"Scam confidence\"] = unlabelled[\"textPreprocessed\"].apply(lambda x: scam_confidence.get(x, None))\n",
    "unlabelled[\"Non-malicious confidence\"] = unlabelled[\"textPreprocessed\"].apply(lambda x: non_mal_confidence.get(x,None))\n",
    "unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_unlabelled = unlabelled[(~unlabelled[\"Scam confidence\"].isna()) & (~unlabelled[\"Non-malicious confidence\"].isna())]\n",
    "# filtered_unlabelled = unlabelled[(~unlabelled[\"Scam confidence\"].isna()) | (~unlabelled[\"Non-malicious confidence\"].isna())]\n",
    "# filtered_unlabelled\n",
    "\n",
    "# Create function to get add top X% of Scam conf instance and top Y% of Non-malicious conf inst to the expanded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_confidence(unlabelled, scam_prop, non_mal_prop):\n",
    "    # print(len(unlabelled)) # 1999, dropped 1 instance due to not having tokens in vocab\n",
    "    confident_scam_instances = unlabelled[unlabelled[\"Scam confidence\"] > 1]\n",
    "    confident_non_mal_instances = unlabelled[unlabelled[\"Non-malicious confidence\"] > 1]\n",
    "\n",
    "    num_scam = int(len(confident_scam_instances) * scam_prop / 100)\n",
    "    num_non_mal = int(len(confident_non_mal_instances) * non_mal_prop / 100)\n",
    "\n",
    "    # Get the indexes of the top scam confidence values\n",
    "    top_scam_idx = confident_scam_instances.nlargest(num_scam, \"Scam confidence\").index\n",
    "    \n",
    "    # Get the indexes of the top non-malicious confidence values\n",
    "    top_non_mal_idx = confident_non_mal_instances.nlargest(num_non_mal, \"Non-malicious confidence\").index\n",
    "\n",
    "    confident_idx = list(set(top_scam_idx).union(top_non_mal_idx))\n",
    "    unlabelled = unlabelled.iloc[confident_idx[0:1998]]\n",
    "    display(unlabelled)\n",
    "\n",
    "    return unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>textPreprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>Scam confidence</th>\n",
       "      <th>Non-malicious confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.014906e-04</td>\n",
       "      <td>4.963010e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>. . . � home home please stay stay citizen ent...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.264532e+00</td>\n",
       "      <td>7.908066e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BankOfAmerica Alert 137943. Please follow http...</td>\n",
       "      <td>. please alert follow re-activate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.289955e+01</td>\n",
       "      <td>1.589837e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry dude. Dont know how i forgot. Even after...</td>\n",
       "      <td>. . . . . sorry sorry dude know forget even re...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.659360e-08</td>\n",
       "      <td>3.760304e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. I dont want to hear anything</td>\n",
       "      <td>. hear anything</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031944e-02</td>\n",
       "      <td>9.690453e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Kay... Since we are out already</td>\n",
       "      <td>already ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.059396e-04</td>\n",
       "      <td>2.463421e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>call now 08707509020 Just 20p per min NTT Ltd...</td>\n",
       "      <td>, call call just rate national per 0870 min 08...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.422397e+12</td>\n",
       "      <td>1.061301e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Are you angry with me. What happen dear</td>\n",
       "      <td>. angry dear happen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.030894e-02</td>\n",
       "      <td>9.700318e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>We r outside already.</td>\n",
       "      <td>. already r outside</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.387732e-03</td>\n",
       "      <td>4.188074e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The Xmas story is peace.. The Xmas msg is love...</td>\n",
       "      <td>.. .. .. u ... story month love &amp; amp ; msg wi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399660e-09</td>\n",
       "      <td>7.144591e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1998 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           textOriginal  \\\n",
       "0     Your opinion about me? 1. Over 2. Jada 3. Kusr...   \n",
       "1     Please Stay At Home. To encourage the notion o...   \n",
       "2     BankOfAmerica Alert 137943. Please follow http...   \n",
       "3     Sorry dude. Dont know how i forgot. Even after...   \n",
       "4                      No. I dont want to hear anything   \n",
       "...                                                 ...   \n",
       "1995                    Kay... Since we are out already   \n",
       "1996   call now 08707509020 Just 20p per min NTT Ltd...   \n",
       "1997            Are you angry with me. What happen dear   \n",
       "1998                              We r outside already.   \n",
       "1999  The Xmas story is peace.. The Xmas msg is love...   \n",
       "\n",
       "                                       textPreprocessed  class  \\\n",
       "0     opinion ? 1 . . . . . . . . . 2 3 4 lovable 5 ...    0.0   \n",
       "1     . . . � home home please stay stay citizen ent...    1.0   \n",
       "2                     . please alert follow re-activate    1.0   \n",
       "3     . . . . . sorry sorry dude know forget even re...    0.0   \n",
       "4                                       . hear anything    0.0   \n",
       "...                                                 ...    ...   \n",
       "1995                                        already ...    0.0   \n",
       "1996  , call call just rate national per 0870 min 08...    1.0   \n",
       "1997                                . angry dear happen    0.0   \n",
       "1998                                . already r outside    0.0   \n",
       "1999  .. .. .. u ... story month love & amp ; msg wi...    0.0   \n",
       "\n",
       "      Scam confidence  Non-malicious confidence  \n",
       "0        2.014906e-04              4.963010e+03  \n",
       "1        1.264532e+00              7.908066e-01  \n",
       "2        6.289955e+01              1.589837e-02  \n",
       "3        2.659360e-08              3.760304e+07  \n",
       "4        1.031944e-02              9.690453e+01  \n",
       "...               ...                       ...  \n",
       "1995     4.059396e-04              2.463421e+03  \n",
       "1996     9.422397e+12              1.061301e-13  \n",
       "1997     1.030894e-02              9.700318e+01  \n",
       "1998     2.387732e-03              4.188074e+02  \n",
       "1999     1.399660e-09              7.144591e+08  \n",
       "\n",
       "[1998 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confident_unlabelled = get_top_confidence(unlabelled, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_data = pd.concat([train_data, confident_unlabelled[[\"textOriginal\", \"textPreprocessed\", \"class\"]]], axis=0)\n",
    "expanded_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_model = create_model(expanded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(model, test):\n",
    "    test_instances = test[\"textPreprocessed\"]\n",
    "    \n",
    "    vocabulary = model[\"vocabulary\"]\n",
    "    prior_probs = model[\"prior_probs\"]\n",
    "    conditional_probs = model[\"conditional_probs\"]\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for test_instance in test_instances:\n",
    "        predicted_label = classify_test_instance(test, vocabulary, test_instance, prior_probs, conditional_probs)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    test[\"predicted class\"] = predicted_labels\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_predictions(test):\n",
    "    test_no_draws = test[test[\"predicted class\"] != 0.5]\n",
    "    class_true = test_no_draws[\"class\"]\n",
    "    class_predict = test_no_draws[\"predicted class\"]\n",
    "    print(classification_report(class_true, class_predict))\n",
    "    cm = confusion_matrix(class_true, class_predict)\n",
    "    print(cm)\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       739\n",
      "           1       0.73      0.89      0.80       146\n",
      "\n",
      "    accuracy                           0.93       885\n",
      "   macro avg       0.85      0.91      0.88       885\n",
      "weighted avg       0.94      0.93      0.93       885\n",
      "\n",
      "[[690  49]\n",
      " [ 16 130]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = predict_dataset(expanded_model, test)\n",
    "report_predictions(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire pipeline\n",
    "def pipeline(train_data, validation_data, unlabelled_data, test_data, confident_prop):\n",
    "    \n",
    "    # Create training model based on training data\n",
    "    train_model = create_model(train_data)\n",
    "\n",
    "    # Use the model to get most confident instances from unlabelled data\n",
    "    scam_confidence, non_mal_confidence = get_top_confident_instances(train_model, unlabelled_data, conf=confident_prop)\n",
    "    unlabelled_data[\"Scam confidence\"] = unlabelled_data[\"textPreprocessed\"].apply(lambda x: scam_confidence.get(x, None))\n",
    "    unlabelled_data[\"Non-malicious confidence\"] = unlabelled_data[\"textPreprocessed\"].apply(lambda x: non_mal_confidence.get(x,None))\n",
    "\n",
    "    confident_unlabelled = get_top_confidence(unlabelled_data, 100, 100)\n",
    "    \n",
    "    expanded_data = pd.concat([train_data, confident_unlabelled[[\"textOriginal\", \"textPreprocessed\", \"class\"]]], axis=0)\n",
    "    expanded_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create expanded model based on supervised data and unlabelled data\n",
    "    expanded_model = create_model(expanded_data)\n",
    "    test_data = predict_dataset(expanded_model, test_data)\n",
    "    report_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sms_supervised_train.csv\")\n",
    "test = pd.read_csv(\"sms_test.csv\")\n",
    "unlabelled = pd.read_csv(\"sms_unlabelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(train, test_size=0.2, random_state=1, stratify=train['class'])\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "validation_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all train, no validation, no unlabelled to classify test (The first version of the model, fully supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       750\n",
      "           1       0.72      0.89      0.80       158\n",
      "\n",
      "    accuracy                           0.92       908\n",
      "   macro avg       0.85      0.91      0.87       908\n",
      "weighted avg       0.93      0.92      0.92       908\n",
      "\n",
      "[[696  54]\n",
      " [ 18 140]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline(train, 0, unlabelled, test, confident_prop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire pipeline\n",
    "def pipeline1(train_data, validation_data, unlabelled_data, test_data):\n",
    "    train_model = create_model(train_data)\n",
    "    test_data = predict_dataset(train_model, test_data)\n",
    "    report_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       752\n",
      "           1       0.93      0.88      0.90       158\n",
      "\n",
      "    accuracy                           0.97       910\n",
      "   macro avg       0.95      0.93      0.94       910\n",
      "weighted avg       0.97      0.97      0.97       910\n",
      "\n",
      "[[741  11]\n",
      " [ 19 139]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline1(train, 0, 0, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Do you get a different result if you iteratively update the model, retraining on only a portion of the unlabelled data each time? For example, use the Q1 model to label 50% of the unlabelled data, retrain, use the retrained model to classify the remaining 50% of the data, and then train the final model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In your write-up, explain your approach and give the reasoning behind your implementation choices.\n",
    "Show results on the training and/or validation set to support your discussion. Your response should be\n",
    "no more than 500 words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
