{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2025 Semester 1\n",
    "\n",
    "## Assignment 1: Scam detection with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     `1352062`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, GRAPHS, AND FIGURES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).** Results, figures, etc. which appear in this file but are NOT included in your report will not be marked.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Infrastructure and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tokens(processed_text):\n",
    "    \"\"\"\n",
    "    Given a preprocessed string/instance, return its tokens and their counts.\n",
    "    \"\"\"\n",
    "    token_counts = dict()\n",
    "    \n",
    "    if isinstance(processed_text, str):\n",
    "        # Split the string into words/tokens\n",
    "        processed_text = processed_text.split(\" \")\n",
    "        # Count the occurrences of each token\n",
    "        for token in processed_text:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "    else:\n",
    "        # Empty string classified as a float for some reason\n",
    "        token_counts = {\"\": 1}\n",
    "\n",
    "    return token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vocabulary(data):\n",
    "    \"\"\"\n",
    "    Find the list of every word which occurs in the  dataset (every word in textPreprocessed)\n",
    "    \"\"\"\n",
    "    vocabulary = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        processed_text = return_tokens(data.loc[i, \"textPreprocessed\"]).keys()\n",
    "        vocabulary = vocabulary + list(processed_text)\n",
    "\n",
    "    vocabulary = sorted(list(set(vocabulary)))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_count_matrix(data, vocabulary):\n",
    "    \"\"\"\n",
    "    Find the count matrix, which is a matrix of size N*V where N is the number of instances in the training data \n",
    "    and V is the number of words in the vocabulary.  \n",
    "    Each cell in the matrix represents the number of times a given word appeared in a given message \n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    # Intialise matrix N*V with 0s\n",
    "    count_matrix = np.zeros((N,V))\n",
    "    count_matrix = pd.DataFrame(count_matrix)\n",
    "    count_matrix.columns = vocabulary\n",
    "\n",
    "    # Iterate over each row - instance \n",
    "    for i in range(N):\n",
    "        instance_token_counts = return_tokens(data.loc[i, \"textPreprocessed\"])\n",
    "        for token in instance_token_counts.keys():\n",
    "            count_matrix.loc[i, token] = instance_token_counts[token]\n",
    "    \n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_prob(data):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of the prior probability of each class P(class)\n",
    "    \"\"\"\n",
    "    prior_probs = dict()\n",
    "\n",
    "    labels = np.unique(data[\"class\"])\n",
    "    for label in labels:\n",
    "        prior_probs[int(label)] = len(data[data[\"class\"]==label])/len(data)\n",
    "\n",
    "    return prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_p_c_i(data, count_matrix, label, word, V=0, alpha=0):\n",
    "    \"\"\"\n",
    "    p(word | label) = count(c,i) + alpha / total(c) + V*alpha\n",
    "    count(c,i) is the total count of times word i appears in messages from class c\n",
    "    total(c) is the total count of words in class c\n",
    "    Alpha is smoothing factor used for Laplace smoothing, defaulted to 0 (no smoothing)\n",
    "    V is the length of the count vector of a test instance\n",
    "    \"\"\"\n",
    "    label_indexes = data[data[\"class\"] == label].index\n",
    "    count_matrix = count_matrix.iloc[label_indexes]\n",
    "    word_counts = np.sum(count_matrix[word]) + alpha\n",
    "    label_counts = np.sum(count_matrix, axis=0).sum() + (V*alpha)\n",
    "    \n",
    "    return float(word_counts / label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conditional_prob(data, vocabulary, count_matrix):\n",
    "    \"\"\"\n",
    "    Return dictionary conditional probabilities of each token in a class\n",
    "    \"\"\"\n",
    "    conditional_probs = {int(label): None for label in data[\"class\"].unique()}\n",
    "    for label in conditional_probs.keys():\n",
    "        conditional_probs[label] = {word: 0 for word in vocabulary}\n",
    "\n",
    "        for word in vocabulary:\n",
    "            conditional_probs[label][word] = calc_p_c_i(data, count_matrix, label, word, V=len(vocabulary))\n",
    "    \n",
    "    return conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_test_count_vector(test_text, vocabulary):\n",
    "    \"\"\"\n",
    "    Find the count vector of a test instance\n",
    "    \"\"\"\n",
    "    count_vector = np.zeros((1, len(vocabulary)))[0]\n",
    "    test_token_counts = return_tokens(test_text)\n",
    "\n",
    "    for i in range(len(vocabulary)):\n",
    "        token = vocabulary[i]\n",
    "        if token in test_token_counts.keys():\n",
    "            count_vector[i] = test_token_counts[token]\n",
    "    \n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_posterior_prob(data, count_vector, vocabulary, prior_probs, conditional_probs):\n",
    "    \"\"\"\n",
    "    Find posterior probability P(class = label | count = count vector) -> P(class = label) * P(count|c)\n",
    "    \"\"\"\n",
    "    posterior_probs = {int(label): None for label in data[\"class\"].unique()}\n",
    "    for label in posterior_probs.keys():\n",
    "        p_class = prior_probs[label]\n",
    "        p_count_c = math.factorial(int(sum(count_vector))) / math.prod([math.factorial(int(x)) for x in count_vector])\n",
    "        test_token_indexes = [i for i in range(len(count_vector)) if count_vector[i] != 0]\n",
    "\n",
    "        for token_index in test_token_indexes:\n",
    "            p_c_i = conditional_probs[label][vocabulary[token_index]]\n",
    "\n",
    "            # Original formula\n",
    "            p_count_c = p_count_c * math.pow(p_c_i, count_vector[token_index])\n",
    "\n",
    "            # Or take log to avoid underflow\n",
    "            # prob = math.pow(p_c_i, count_vector[token_index])\n",
    "            # if prob == 0:\n",
    "            #     p_count_c = p_count_c + 0\n",
    "            # else:\n",
    "            #     p_count_c = p_count_c + math.log(prob)\n",
    "            \n",
    "        p_c_count = p_class * p_count_c\n",
    "        posterior_probs[label] = p_c_count\n",
    "\n",
    "    return posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_instance(data, vocabulary, test_text, prior_probs, conditional_probs):\n",
    "    \"\"\"\n",
    "    Given a string, classify it as 0 - non malicious, or 1 - scam\n",
    "    \"\"\"\n",
    "    test_count_vector = find_test_count_vector(test_text, vocabulary)\n",
    "\n",
    "    # Count vector all zeroes so cannot classify\n",
    "    if np.count_nonzero(test_count_vector) == 0:\n",
    "        print(\"Cannot classify\")\n",
    "        return None\n",
    "    \n",
    "    test_posterior_prob = find_posterior_prob(data, test_count_vector, vocabulary, prior_probs, conditional_probs)\n",
    "    # Find which class has higher likelihood\n",
    "    best_label = None\n",
    "    best_prob = 0\n",
    "\n",
    "    # If both are equal, return 0.5, hard coded \n",
    "    if test_posterior_prob[0] == test_posterior_prob[1]:\n",
    "        return 0.5\n",
    "\n",
    "    for label, prob_label in test_posterior_prob.items():\n",
    "        if prob_label > best_prob:\n",
    "            best_prob = prob_label\n",
    "            best_label = label\n",
    "    \n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_prob_ratio(c1, c2, vocabulary, conditional_probs, top=10):\n",
    "    ratios = dict()\n",
    "\n",
    "    for word in vocabulary:\n",
    "        p_c1_i = conditional_probs[c1][word]\n",
    "        p_c2_i = conditional_probs[c2][word]\n",
    "        if p_c2_i != 0:\n",
    "            r = p_c1_i / p_c2_i\n",
    "            ratios[word] = r\n",
    "\n",
    "    top_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    top_ratios = dict(top_ratios)\n",
    "\n",
    "    return top_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_test_ratios(data, vocabulary, prior_probs, conditional_probs, c1, c2, boundary=False, top=3):\n",
    "    ratios = dict()\n",
    "\n",
    "    for test_text in data[\"textPreprocessed\"]:\n",
    "        test_count_vector = find_test_count_vector(test_text, vocabulary)\n",
    "        test_posterior_prob = find_posterior_prob(data, test_count_vector, vocabulary, prior_probs, conditional_probs)\n",
    "        post_c1 = test_posterior_prob[c1]\n",
    "        post_c2 = test_posterior_prob[c2]\n",
    "\n",
    "        if post_c2 != 0:\n",
    "            r = post_c1/post_c2\n",
    "            ratios[test_text] = r\n",
    "\n",
    "    if not boundary:\n",
    "        top_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    else:\n",
    "        top_ratios = sorted(ratios.items(), key=lambda x: abs(x[1] - 1))[:top]\n",
    "\n",
    "    top_ratios = dict(top_ratios)\n",
    "    return top_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sms_supervised_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = find_vocabulary(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = find_count_matrix(train, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = find_prior_prob(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probs = find_conditional_prob(train, vocabulary, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.0000000000000027)\n",
      "(1, 0.9999999999999903)\n"
     ]
    }
   ],
   "source": [
    "# check if prob within each class label sum = 1\n",
    "for label in conditional_probs.keys():\n",
    "    print((label, sum(conditional_probs[label].values())))\n",
    "# good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the prior probabilities of the classes P(c) in the training dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8, 1: 0.2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the most probable words in each class? List about 10 per class and their probability values p(c,i)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 probable words in class 0\n",
      "1. P(,|class = 0) = 0.02925414538805876\n",
      "2. P(?|class = 0) = 0.028749763571023264\n",
      "3. P(u|class = 0) = 0.021247084042620264\n",
      "4. P(...|class = 0) = 0.02105794086123195\n",
      "5. P(!|class = 0) = 0.01929260450160772\n",
      "6. P(..|class = 0) = 0.016770695416430236\n",
      "7. P(;|class = 0) = 0.014753168148288254\n",
      "8. P(&|class = 0) = 0.014690120421158817\n",
      "9. P(go|class = 0) = 0.012483449971628523\n",
      "10. P(get|class = 0) = 0.011096399974780909\n",
      "\n",
      "\n",
      "Top 10 probable words in class 1\n",
      "1. P(!|class = 1) = 0.031002363408869735\n",
      "2. P(,|class = 1) = 0.029890170999582927\n",
      "3. P(call|class = 1) = 0.026136521618239955\n",
      "4. P(£|class = 1) = 0.017656054497428054\n",
      "5. P(free|class = 1) = 0.01334630891144168\n",
      "6. P(/|class = 1) = 0.011538996246350618\n",
      "7. P(2|class = 1) = 0.011121924092868066\n",
      "8. P(&|class = 1) = 0.010982900041707216\n",
      "9. P(?|class = 1) = 0.010704851939385513\n",
      "10. P(claim|class = 1) = 0.009731683581259558\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_conditional_probs = {}\n",
    "\n",
    "for label in conditional_probs:\n",
    "    prob_dict = conditional_probs[label]\n",
    "    sorted_items = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_conditional_probs[label] = dict(sorted_items)  \n",
    "\n",
    "for label in sorted_conditional_probs:\n",
    "    print(f\"Top 10 probable words in class {label}\")\n",
    "    for i in range(1, 11):\n",
    "        token = list(sorted_conditional_probs[label].keys())[i]\n",
    "        print(f\"{i}. P({token}|class = {label}) = {sorted_conditional_probs[label][token]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What individual words are most strongly predictive of each class? List the words and the probability ratios R. Ignore ratios where the denominator = 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What 10 words are most strongly predictive of the scam (label=1) class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 77.17711664117893,\n",
       " 'award': 70.56193521479217,\n",
       " '£': 70.0106700959266,\n",
       " 'cs': 48.51133046016962,\n",
       " '1000': 41.89614903378285,\n",
       " '150p': 39.691088558320594,\n",
       " 'entry': 39.691088558320594,\n",
       " '100': 35.280967607396086,\n",
       " 'contact': 30.870846656471567,\n",
       " 'service': 30.13582649798415}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_prob_ratio(c1=1, c2=0, vocabulary=vocabulary, conditional_probs=conditional_probs, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What 10 words are most strongly predictive non-malicious (label=0) class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 106.11953849063741,\n",
       " '...': 75.73488430742071,\n",
       " 'ok': 43.08271861799382,\n",
       " 'sorry': 25.849631170796293,\n",
       " 'ask': 24.94262656831221,\n",
       " 'come': 20.86110585713385,\n",
       " 'k': 18.14009204968161,\n",
       " 'leave': 15.872580543471408,\n",
       " 'really': 14.512073639745285,\n",
       " 'say': 14.05857133850325}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_prob_ratio(c1=0, c2=1, vocabulary=vocabulary, conditional_probs=conditional_probs, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss results. Do they seem reasonable? Do you think it will be possible to distinguish the 2 classes using the multinomial naive Bayes model? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the most probable words in each class, the top 10 most probable words in each class are filled with punctuation tokens instead of actual words, making it hard to distinguish the 2 classes using this specific Bayes Model. For example, the \"!\" token, appears relatively frequently in both classes, with a probability of approx. 2% and 3% respectively.\n",
    "Thus, more text preprocessing may be needed to reduce the dimensionality of our attributes/tokens/vocabulary, which may result in a more realistic representation of probable words within each label.\n",
    "\n",
    "However, results from the ratio R calculations seem promising and reasonable. The words most strongly predictive of the scam class include \"claim\", \"award\", \"service\", \"£\", which may correspond to typical rewards/money related phishing scams, which is to be expected. Likewise, words most strongly predictive of the non-malicious class such as \"ok\", \"k\", \"sorry\" are typically seen in everyday texts and conversations. \n",
    "\n",
    "Ultimately, it is possible to distinguish the 2 classes using the multinomial naive Bayes model, however, in our specific infrastructure/setup, more data preprocessing of the raw sms could further enhance the model's ability to differentiate between class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"sms_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = test[\"textPreprocessed\"]\n",
    "predicted_labels = []\n",
    "for test_instance in test_instances:\n",
    "    predicted_label = classify_test_instance(test, vocabulary, test_instance, prior_probs, conditional_probs)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "test[\"predicted class\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Report the overall accuracy of your classifier as well as a breakdown by class (e.g. using a confusion matrix or by reporting precision and recall)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove instances where the model could not decide between class 0 or 1 (predict 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_draws = test[test[\"predicted class\"] != 0.5]\n",
    "class_true = test_no_draws[\"class\"]\n",
    "class_predict = test_no_draws[\"predicted class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       752\n",
      "           1       0.93      0.88      0.90       158\n",
      "\n",
      "    accuracy                           0.97       910\n",
      "   macro avg       0.95      0.93      0.94       910\n",
      "weighted avg       0.97      0.97      0.97       910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(class_true, class_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[741  11]\n",
      " [ 19 139]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(class_true, class_predict)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy = (741+139)/(741+139+11+19) = 0.967 = 0.97, matching the classification report\n",
    "\n",
    "Class 0:\n",
    "- Recall = 0.99\n",
    "- Precision = 0.97\n",
    "\n",
    "Class 1:\n",
    "- Recall = 0.88\n",
    "- Precision = 0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Report how often your model encountered out-of-vocabulary words in the test set. Were any test items skipped (not classified) due to this problem?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trouble': 1, '2nite': 5, 'hmv': 1, 'law': 2, 'plot': 1, 'pie': 3, 'drivin': 3, 'realise': 1, 'hook': 3, 'nearly': 1, 'fetch': 1, 'activity': 2, 'inside': 3, 'greet': 1, 'grl': 1, 'manage': 2, '87131': 1, 'journey': 1, 'require': 2, '://': 3, 'daddy': 4, 'asleep': 4, 'market': 2, 'depend': 1, 'prabha': 1, 'wed': 2, 'title': 1, 'piece': 1, 'fault': 3, 'lift': 2, 'girlfrnd': 1, 'boston': 2, 'nyc': 2, 't-mobile': 3, '0845': 2, 'skype': 2, 'mini': 2, 'postcode': 1, 'dreams': 3, 'lmao': 2, 'armand': 1, '1956669': 2, 'possession': 2, 'feelin': 1, 'befor': 1, 'ru': 1, 'sen': 1, 'fire': 1, 'definitely': 1, 'legal': 2, 'holla': 3, 'sup': 1, 'dick': 2, 'harry': 1, 'oz': 3, 'yijue': 1, 'exactly': 2, 'bet': 1, 'esplanade': 2, 'bud': 1, 'din': 2, 'act': 3, '=d': 1, 'challenge': 1, 'wet': 1, '6hrs': 3, '7250i': 1, '0578': 2, 'annoying': 2, 'calling': 3, 'rally': 2, 'pack': 1, 'empty': 3, 'fyi': 2, '81151': 1, 'report': 1, 'gram': 1, 'lay': 2, 'yahoo': 1, 'experience': 2, 'fee': 1, 'k.': 2, 'pg': 1, 'ec2a': 1, 'woke': 2, 'realy': 1, 'lecture': 1, 'cancer': 1, 'fromm': 1, 'aiyar': 1, 'ta': 1, '32': 1, 'infernal': 1, 'affair': 1}\n",
      "Number of unique tokens not classifed = 94\n",
      "Number of instances model encountered out-of-vocab during testing = 160\n"
     ]
    }
   ],
   "source": [
    "test_out_of_vocab = dict()\n",
    "for i in range(len(test)):\n",
    "    text = test.loc[i, \"textPreprocessed\"]\n",
    "    text_tokens = return_tokens(text)\n",
    "    tokens_out_of_vocab = 0\n",
    "\n",
    "    for token in text_tokens:\n",
    "        if token not in vocabulary:\n",
    "            tokens_out_of_vocab += 1\n",
    "            if token not in test_out_of_vocab.keys():\n",
    "                test_out_of_vocab[token] = 1\n",
    "            else:\n",
    "                test_out_of_vocab[token] += 1\n",
    "\n",
    "print(test_out_of_vocab)\n",
    "print(f\"Number of unique tokens not classifed = {len(test_out_of_vocab)}\")\n",
    "print(f\"Number of instances model encountered out-of-vocab during testing = {sum(test_out_of_vocab.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 test instances skipped\n"
     ]
    }
   ],
   "source": [
    "num_tests_skipped = len(test[test[\"predicted class\"].isna()])\n",
    "print(f\"There were {num_tests_skipped} test instances skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Provide examples of instances classified with high low confidence using ratio of posterior likelihood for each class. Provide some examples of test instances which are:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. classified scam (label=1) with high confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: . . . 2 ur yes ! £ £ offer claim last chance t 250 16 mobile discount worth cs sub 3.00\n",
      "R score: 1218556157491979.2\n",
      "\n",
      "2.\n",
      "Text: reply reply free re call new offer delivery phone 150 750 tomorrow try contact video min\n",
      "R score: 72050987442.02776\n",
      "\n",
      "3.\n",
      "Text: ? . 4 4 u week £ txt new question name 100 draw thanks enter cash continue support an\n",
      "R score: 322011806.0440202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=1, c2=0)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. classified non-malicious (label=0) with high confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: come , back back ... ... babe\n",
      "R score: 3496694.2349932324\n",
      "\n",
      "2.\n",
      "Text: ? come u pick ok n\n",
      "R score: 501137.3137662168\n",
      "\n",
      "3.\n",
      "Text: ok go ... change\n",
      "R score: 281369.3755832117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=0, c2=1)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. on the boundary between the 2 classes (R near 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: 4 ! ! mate money\n",
      "R score: 0.916100252108639\n",
      "\n",
      "2.\n",
      "Text: . send link picture\n",
      "R score: 0.8252714568964516\n",
      "\n",
      "3.\n",
      "Text: . yes chat\n",
      "R score: 1.2034878671644293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=1, c2=0, boundary=True)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Text: 4 ! ! mate money\n",
      "R score: 1.091583587820486\n",
      "\n",
      "2.\n",
      "Text: . yes chat\n",
      "R score: 0.8309182230113605\n",
      "\n",
      "3.\n",
      "Text: . send link picture\n",
      "R score: 1.2117225085678347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = find_top_test_ratios(test, vocabulary, prior_probs, conditional_probs, c1=0, c2=1, boundary=True)\n",
    "for i, (text, R) in enumerate(result.items(), start=1):\n",
    "    print(f\"{i}.\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"R score: {R}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here, we should expect to receive the same texts regardless of what c1 or c2 is, which is true, as shown in results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition to reporting these points, briefly interpret them. Do the model’s high and low confidence\n",
    "predictions seem reasonable to you? Is one class easier to identify than the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well, having high accuracy and recall/precision per class in the test set. Looking at both recall and precision factors, i.e., the f1 score, the model performs better at predicting non-malicious texts (0.98), compared to scam texts (0.90). The difference may be due to class imbalance in the training set (80/20), where non malicious texts appear more than scams. Because of less occurances of scam instances, the model might not be as well trained on the minority class where there are less examples.\n",
    "\n",
    "The model's predictive capability can be further improved by having larger training datasets which reduce the number of unique tokens that cannot be identified in the test dataset. Fortunately, this issue did not lead to any non-classifications/skips in testing.\n",
    "\n",
    "Additionally, the model's confidence values seem reasonable. The top 3 results in the scam predictions have extremely high confidence, and the contents of the texts reflect this confidence value, tokens such as \"claim\", \"discount\", \"offer\", \"cash\"... are indicative of scam attempts. \n",
    "While there is also high confidence in non-malicious predictions, the degree/magnitude of confidence in scam instances is much higher, where the highest R score of label=0 is approx  3,500,000, compared to approx 1.22E12 in the scam class, almost a million times larger (looking at the number of extra 0s).\n",
    "\n",
    "In summary, based on f1, the model performs better when predicting non-malicious texts, however, looking at confidence, the model is more confident in the scam class, possibly due to more pronounced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extending the model with semi-supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled = pd.read_csv(\"sms_unlabelled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
